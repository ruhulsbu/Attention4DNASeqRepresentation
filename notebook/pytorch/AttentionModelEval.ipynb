{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "#import pandas as pd\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_index(data, label):\n",
    "    rand_index = np.random.permutation(len(data))\n",
    "    \n",
    "    data = np.array([data[i] for i in rand_index])\n",
    "    label = np.array([label[i] for i in rand_index])\n",
    "    \n",
    "    return (data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "# Read the Input File\n",
    "max_data_size = 1527294\n",
    "\n",
    "def read_input_file(file_path, label=-1):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    file_read = open(file_path, \"r\")\n",
    "    for line in file_read:\n",
    "        data = [int(i) for i in line.strip()]\n",
    "        x_data.append(data)\n",
    "        y_data.append(label)\n",
    "        #print(x_data[-1], y_data[-1])\n",
    "        if len(x_data) == max_data_size:\n",
    "            break\n",
    "    file_read.close()\n",
    "    print(\"Sequences Read: \", len(x_data))\n",
    "    return np.array(x_data), np.array(y_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences Read:  1527294\n",
      "Sequences Read:  1527294\n",
      "Sequences Read:  1527294\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/mnt/scratch7/hirak/\"\n",
    "x_data_pos_full, y_data_pos_full = read_input_file(os.path.join(root_dir, \"Attention4DNASeqRepresentation/dataset/gene_range_start_codon.txt\"), 1)\n",
    "\n",
    "original_neg_intergenic_data, original_neg_intergenic_label = read_input_file(os.path.join(root_dir, \"Attention4DNASeqRepresentation/dataset/intragenic_start_codon.txt\"), 0)\n",
    "original_neg_coding_data, original_neg_coding_label = read_input_file(os.path.join(root_dir, \"Attention4DNASeqRepresentation/dataset/coding_start_codon.txt\"), 0)\n",
    "\n",
    "x_data_neg_full = np.concatenate((original_neg_coding_data, original_neg_intergenic_data))\n",
    "y_data_neg_full = np.concatenate((original_neg_coding_label, original_neg_intergenic_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_neg_full, y_data_neg_full = randomized_index(x_data_neg_full, y_data_neg_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences Read:  1527294\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/mnt/scratch7/hirak/\"\n",
    "\n",
    "x_data_neg_one, y_data_neg_one = read_input_file(os.path.join(root_dir, \"Attention4DNASeqRepresentation/dataset/intragenic_start_codon.txt\"), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_neg_pos(label):\n",
    "    pos, neg = 0, 0\n",
    "    for l in label:\n",
    "        if l == 0:\n",
    "            neg += 1\n",
    "        else:\n",
    "            pos += 1\n",
    "    print(\"neg: {}, pos {}\".format(neg, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(data_size=1000, batch_size = 100, only_intergenic = False):\n",
    "    \n",
    "\n",
    "    x_data_pos = x_data_pos_full[:data_size]\n",
    "    y_data_pos = y_data_pos_full[:data_size]\n",
    "\n",
    "    if(only_intergenic):\n",
    "        x_data_neg = x_data_neg_one[:data_size]\n",
    "        y_data_neg = y_data_neg_one[:data_size]\n",
    "    else:\n",
    "        x_data_neg = x_data_neg_full[:data_size]\n",
    "        y_data_neg = y_data_neg_full[:data_size]\n",
    "\n",
    "        \n",
    "    rand_index = np.random.permutation(data_size)\n",
    "    x_data_pos = [x_data_pos[i] for i in rand_index]\n",
    "    y_data_pos = [y_data_pos[i] for i in rand_index]\n",
    "\n",
    "    x_data_neg = [x_data_neg[i] for i in rand_index]\n",
    "    y_data_neg = [y_data_neg[i] for i in rand_index]\n",
    "    # np.random.shuffle(x_data_neg)\n",
    "    # np.random.shuffle(x_data_pos)\n",
    "\n",
    "    train_index = int((len(x_data_pos) / batch_size) * 0.60 * batch_size)\n",
    "    eval_index = train_index + int((len(x_data_pos) / batch_size) * 0.20 * batch_size)\n",
    "    test_index = eval_index + int((len(x_data_pos) / batch_size) * 0.20 * batch_size)\n",
    "\n",
    "    print(\"train, eval, test = \", (train_index, eval_index, test_index))\n",
    "\n",
    "    #Process Negative Data\n",
    "\n",
    "    x_train = x_data_neg[0:train_index]\n",
    "    y_train = y_data_neg[0:train_index]\n",
    "\n",
    "    x_eval = x_data_neg[train_index:eval_index]\n",
    "    y_eval = y_data_neg[train_index:eval_index]\n",
    "\n",
    "    x_test = x_data_neg[eval_index:test_index]\n",
    "    y_test = y_data_neg[eval_index:test_index]\n",
    "\n",
    "    #Process Positive Data\n",
    "\n",
    "    x_train = np.append(x_train, x_data_pos[0:train_index], axis=0)\n",
    "    y_train = np.append(y_train, y_data_pos[0:train_index], axis=0)\n",
    "\n",
    "    x_eval = np.append(x_eval, x_data_pos[train_index:eval_index], axis=0)\n",
    "    y_eval = np.append(y_eval, y_data_pos[train_index:eval_index], axis=0)\n",
    "\n",
    "    x_test = np.append(x_test, x_data_pos[eval_index:test_index], axis=0)\n",
    "    y_test = np.append(y_test, y_data_pos[eval_index:test_index], axis=0)\n",
    "    \n",
    "    #Randomize data\n",
    "    x_train, y_train = randomized_index(x_train, y_train)\n",
    "    x_eval, y_eval = randomized_index(x_eval, y_eval)\n",
    "    x_test, y_test = randomized_index(x_test, y_test)\n",
    "    \n",
    "\n",
    "    print(\"Sanity Check: \", np.sum(y_train), np.sum(y_eval), np.sum(y_test))\n",
    "\n",
    "    return (x_train, y_train, x_eval, y_eval, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(F.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):#corrected batch faster\n",
    "    #(self, time_steps, embedding_dim, hidden_dim, vocab_size, tagset_size, mini_batch)\n",
    "    def __init__(self, vocab_size, embedding_dim, \\\n",
    "                 hidden_dim, device, batch_size=100, debug=1, \\\n",
    "                 tagset_size=1, time_steps=101):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.time_steps = time_steps\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.minibatch_size = batch_size\n",
    "        self.dropout_p = 0.25\n",
    "        self.tagset_size = tagset_size\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.hidden_bi = self.init_hidden(bidirectional=True)\n",
    "        self.debug = debug\n",
    "        self.device = device \n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm_one = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout_one = nn.Dropout(0.4)\n",
    "        self.lstm_two = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout_two = nn.Dropout(0.4)\n",
    "        self.lstm_three = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout_three = nn.Dropout(0.4)\n",
    "\n",
    "        self.attn_array = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for i in range(time_steps)])\n",
    "        \n",
    "        self.lstm_four = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional = True)\n",
    "        self.dropout_seven = nn.Dropout(0.4)\n",
    "        \n",
    "        self.lstm_five = nn.LSTM(hidden_dim*2, hidden_dim*2, batch_first=True, bidirectional = True)\n",
    "        self.dropout_eight = nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        self.attn_combine = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        #embedding_dim*time_steps\n",
    "        \"\"\"\n",
    "\n",
    "        self.hidden2tag_one = nn.Linear(hidden_dim*2*time_steps, 512)\n",
    "        self.dropout_four = nn.Dropout(0.25)\n",
    "        self.hidden2tag_two = nn.Linear(512, 128)\n",
    "        self.dropout_five = nn.Dropout(0.25)\n",
    "        self.hidden2tag_three = nn.Linear(128, 64)\n",
    "        self.dropout_six = nn.Dropout(0.25)\n",
    "\n",
    "        self.output = nn.Linear(64, tagset_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        init_embed = self.embedding(input)\n",
    "        #embedded = init_embed.permute(1, 0, 2)\n",
    "        if self.debug == 1:\n",
    "            print(\"Embedding Shape: \", init_embed.shape)\n",
    "\n",
    "        lstm_out, self.hidden_one = self.lstm_one(init_embed, self.hidden)\n",
    "        lstm_out = self.dropout_one(lstm_out)\n",
    "        lstm_out, self.hidden_two = self.lstm_two(lstm_out, self.hidden)\n",
    "        lstm_out = self.dropout_two(lstm_out)\n",
    "        lstm_out, self.hidden_three = self.lstm_three(lstm_out, self.hidden)\n",
    "        lstm_out = self.dropout_three(lstm_out)\n",
    "        #\"\"\"\n",
    "        lstm_permute = lstm_out.permute(1, 0, 2)\n",
    "        if self.debug == 1:\n",
    "            print(\"LSTM Out Shape: \", lstm_permute.shape)\n",
    "\n",
    "        attention = [self.attn_array[i](lstm_permute[i][:]) for i in range(self.time_steps)]\n",
    "        attention = torch.stack(attention)\n",
    "        attention.to(device)\n",
    "        \n",
    "        attention = attention.permute(1, 0, 2)\n",
    "        if self.debug == 1:\n",
    "            print(\"Attention Shape: \", attention.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        attn_weights = F.softmax(attention, dim=2)\n",
    "        #attn_weights = attn_weights.view(self.minibatch_size, self.time_steps, 1)\n",
    "        if self.debug == 1:\n",
    "            print(\"Softmax Shape: \", attn_weights.shape)\n",
    "        \"\"\"\n",
    "        attn_weights = torch.stack(\n",
    "            [attn_weights]*self.embedding_dim, 2).view(\n",
    "            self.minibatch_size, self.time_steps, -1)\n",
    "        if self.debug == 1:\n",
    "            print(\"Softmax ReShape: \", attn_weights.shape)\n",
    "        \"\"\"\n",
    "        #attn_applied = init_embed\n",
    "        attn_applied = attn_weights * init_embed\n",
    "        \n",
    "        # potential lstm \n",
    "        if self.debug == 1:\n",
    "            print(\"Attention Applied Shape: \", attn_applied.shape)\n",
    "\n",
    "        lstm_out, self.hidden_one = self.lstm_four(attn_applied, self.hidden_bi)\n",
    "        lstm_out = self.dropout_seven(lstm_out)\n",
    "        if self.debug == 1:\n",
    "            print(\"LSTM out: \", lstm_out.shape)\n",
    "        # lstm_out, self.hidden_two = self.lstm_five(lstm_out, self.hidden_bi)\n",
    "        # lstm_out = self.dropout_eight(lstm_out)    \n",
    "        \n",
    "        #attn_applied = attn_applied.view(self.minibatch_size, self.time_steps, -1)\n",
    "        #attn_applied = torch.sum(attn_applied, dim=1)\n",
    "        if self.debug == 1:\n",
    "            print(\"Embedding*Attention Shape: \", attn_applied.shape)\n",
    "\n",
    "        #output = F.relu(attn_applied)\n",
    "        #\"\"\"\n",
    "\n",
    "        # lstm_out = attn_applied.contiguous().view(self.minibatch_size, -1)\n",
    "        lstm_out = lstm_out.contiguous().view(self.minibatch_size, -1)\n",
    "        if self.debug == 1:\n",
    "            print(\"LSTM Output Shape: \", lstm_out.shape)\n",
    "\n",
    "\n",
    "        dense_out = self.hidden2tag_one(lstm_out[:])\n",
    "        dense_out = F.relu(dense_out[:])\n",
    "        dense_out = self.dropout_four(dense_out[:])\n",
    "\n",
    "        dense_out = self.hidden2tag_two(dense_out[:])\n",
    "        dense_out = F.relu(dense_out[:])\n",
    "        dense_out = self.dropout_five(dense_out[:])\n",
    "\n",
    "        dense_out = self.hidden2tag_three(dense_out[:])\n",
    "        dense_out = F.relu(dense_out[:])\n",
    "        dense_out = self.dropout_six(dense_out[:])\n",
    "\n",
    "        tag_space = self.output(dense_out[:])\n",
    "        #print(tag_space.shape)\n",
    "        #tag_scores = F.sigmoid(tag_space)\n",
    "        #tag_scores = F.softmax(tag_space, dim=1)\n",
    "        #print(tag_scores.shape)\n",
    "        return tag_space, attn_applied\n",
    "\n",
    "    def init_hidden(self, bidirectional = False):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        if(bidirectional):\n",
    "            return (torch.zeros(2, self.minibatch_size, self.hidden_dim, device = device),\n",
    "                    torch.zeros(2, self.minibatch_size, self.hidden_dim, device = device))\n",
    "        else:\n",
    "            return (torch.zeros(1, self.minibatch_size, self.hidden_dim, device = device),\n",
    "                    torch.zeros(1, self.minibatch_size, self.hidden_dim, device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, eval, test =  (600000, 800000, 1000000)\n",
      "Sanity Check:  600000 200000 200000\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "data_size = 1000000\n",
    "batch_size = 1000\n",
    "\n",
    "x_train, y_train, x_eval, y_eval, x_test, y_test = load_data(data_size, batch_size, only_intergenic=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200000, 101), (400000, 101), (400000, 101))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_eval.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: 600000, pos 600000\n"
     ]
    }
   ],
   "source": [
    "check_neg_pos(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: 200000, pos 200000\n"
     ]
    }
   ],
   "source": [
    "check_neg_pos(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hirak/miniconda2/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:1380: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = AttnDecoderRNN(5, 16, 16, device, batch_size=batch_size, debug=0)\n",
    "#model = model.cuda()\n",
    "model.to(device)\n",
    "\n",
    "X = torch.from_numpy(np.array(x_train).astype(int))\n",
    "Y = torch.from_numpy(np.array(y_train).reshape(len(y_train),1).astype(np.int))\n",
    "\n",
    "X_test = torch.from_numpy(np.array(x_test).astype(int))\n",
    "Y_test = torch.from_numpy(np.array(y_test).reshape(len(y_test),1).astype(np.int))\n",
    "\n",
    "X, Y = X.to(device), Y.to(device)\n",
    "X_test, Y_test = X_test.to(device), Y_test.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "num_epochs = 50\n",
    "losses = []\n",
    "\n",
    "accuracy_test = []\n",
    "\n",
    "for epoch in range(num_epochs):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    tot_test_acc = 0\n",
    "\n",
    "    for index in range(0, len(X), batch_size):\n",
    "        sentence = X[index : index+batch_size]#.reshape(len(X[0]))\n",
    "        tags = Y[index : index+batch_size]#.reshape(len(Y[0]))\n",
    "        sentence.to(device)\n",
    "        tags.to(device)\n",
    "        #print(sentence.shape, tags.shape)\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        # sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        #targets = prepare_sequence(tags, tag_to_ix)\n",
    "        targets = tags.float().flatten()\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores, attn_weight = model(sentence)\n",
    "        tag_scores = tag_scores.flatten()\n",
    "        #print(targets.shape, tag_scores.shape)\n",
    "\n",
    "        #neg_weight = batch_size / (batch_size-np.sum(data_label[index : index+batch_size]))\n",
    "        #pos_weight = batch_size / np.sum(data_label[index : index+batch_size])\n",
    "        #weights = torch.FloatTensor([neg_weight, pos_weight])\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = criterion(tag_scores, targets)\n",
    "        #loss = weighted_binary_cross_entropy(tag_scores, targets, weights=weights)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        acc = binary_accuracy(tag_scores, targets)\n",
    "        total_acc += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1,num_epochs, loss.data[0], correct/x.shape[0]))\n",
    "\n",
    "\n",
    "    # run forward on this epoch\n",
    "    \n",
    "    for index in range(0, len(X_test), batch_size):\n",
    "        sentence = X_test[index : index+batch_size]#.reshape(len(X[0]))\n",
    "        tags = Y_test[index : index+batch_size]#.reshape(len(Y[0]))\n",
    "        sentence.to(device)\n",
    "        tags.to(device)\n",
    "        #model.hidden = model.init_hidden()\n",
    "        tag_scores_test, attn_weight_test = model(sentence)\n",
    "        tot_test_acc += binary_accuracy(tag_scores_test.flatten(), tags.float().flatten())\n",
    "    \n",
    "    accuracy_test.append(tot_test_acc/(len(X_test)/batch_size))\n",
    "\n",
    "    losses.append(total_loss)\n",
    "    accuracies.append(total_acc/(len(X)/batch_size))\n",
    "\n",
    "    #total_loss.backward()\n",
    "    #opt.step()\n",
    "\n",
    "    #print(epoch, total_loss)#, total_acc)\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}, Test Accuracy {:.3f}\".format(epoch+1,num_epochs, losses[-1], accuracies[-1], accuracy_test[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

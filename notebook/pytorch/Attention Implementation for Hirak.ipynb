{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from util import basic\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4273, -0.5860, -1.1210, -2.2975,  0.3159],\n",
      "         [-1.1645,  0.1066, -1.5642,  2.6369,  1.5461],\n",
      "         [-0.8413,  0.7559,  0.2563,  0.6071, -2.2008]],\n",
      "\n",
      "        [[ 0.0217, -1.1420, -1.8345, -0.5267, -0.3057],\n",
      "         [ 0.7530,  1.3931,  1.4808,  0.2028,  0.0197],\n",
      "         [-1.0759, -1.6855,  1.3726,  0.0447, -0.9492]]])\n",
      "torch.Size([2, 3, 5])\n",
      "torch.Size([3, 2, 5])\n",
      "tensor([[[ 0.4273, -0.5860, -1.1210, -2.2975,  0.3159],\n",
      "         [ 0.0217, -1.1420, -1.8345, -0.5267, -0.3057]],\n",
      "\n",
      "        [[-1.1645,  0.1066, -1.5642,  2.6369,  1.5461],\n",
      "         [ 0.7530,  1.3931,  1.4808,  0.2028,  0.0197]],\n",
      "\n",
      "        [[-0.8413,  0.7559,  0.2563,  0.6071, -2.2008],\n",
      "         [-1.0759, -1.6855,  1.3726,  0.0447, -0.9492]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "print(x)\n",
    "print(x.size())\n",
    "y = x.permute(1, 0, 2)\n",
    "print(y.size())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_pos_data, original_pos_label = basic.preprocess_data(\"/mnt/scratch7/hirak/Attention4DNASeqRepresentation/dataset/gene_range_start_codon.txt\", 1)\n",
    "original_neg_data, original_neg_label = basic.preprocess_data(\"/mnt/scratch7/hirak/Attention4DNASeqRepresentation/dataset/intragenic_start_codon.txt\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_data = dataset.loc[dataset.label == 1].gene.values\n",
    "#pos_label = dataset.loc[dataset.label == 1].label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neg_data = dataset.loc[dataset.label == 0].gene.values\n",
    "#neg_label = dataset.loc[dataset.label == 0].label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527294 2242562\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "print(len(original_pos_data), len(original_neg_data))\n",
    "print(original_pos_label[0], original_neg_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 1000\n",
      "2000 10\n",
      "2000 1000\n"
     ]
    }
   ],
   "source": [
    "data_size = 1000\n",
    "batch_size = 10\n",
    "data_content = original_pos_data[:data_size] + original_neg_data[:data_size]\n",
    "pos_data = None\n",
    "neg_data = None\n",
    "data_label = original_pos_label[:data_size] + original_neg_label[:data_size] \n",
    "pos_label = None\n",
    "neg_label = None\n",
    "print(len(data_content), np.sum(data_label))\n",
    "\n",
    "total_datasize = len(data_content)-len(data_content)%batch_size\n",
    "print(total_datasize, batch_size)\n",
    "rand_index = np.random.permutation(total_datasize)\n",
    "data_content = [data_content[i] for i in rand_index]\n",
    "data_label = [data_label[i] for i in rand_index]\n",
    "print(len(data_content), np.sum(data_label))\n",
    "# '''\n",
    "# for i in range(len(data_label)):\n",
    "#     if data_label[i] == 1:\n",
    "#         data_content[i] = [data_content[i][0] for k in data_content[i]]\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_content[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Basic Attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 101]), torch.Size([2000, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.from_numpy(np.array(data_content).astype(int))\n",
    "Y = torch.from_numpy(np.array(data_label).reshape(len(data_label),1).astype(np.int))\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):#corrected batch faster\n",
    "    #(self, time_steps, embedding_dim, hidden_dim, vocab_size, tagset_size, mini_batch)\n",
    "    def __init__(self, vocab_size, embedding_dim, \\\n",
    "                 hidden_dim, batch_size=100, debug=1, \\\n",
    "                 tagset_size=1, time_steps=101):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.time_steps = time_steps\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.minibatch_size = batch_size\n",
    "        self.dropout_p = 0.25\n",
    "        self.tagset_size = tagset_size\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.debug = debug\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm_one = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout_one = nn.Dropout(0.25)\n",
    "        self.lstm_two = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout_two = nn.Dropout(0.25)\n",
    "        \n",
    "        self.attn_array = [nn.Linear(hidden_dim, hidden_dim) for i in range(time_steps)]\n",
    "        \"\"\"\n",
    "        self.attn_combine = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        #embedding_dim*time_steps\n",
    "        \"\"\"\n",
    "        \n",
    "        self.hidden2tag_one = nn.Linear(hidden_dim*time_steps, 512)\n",
    "        self.dropout_three = nn.Dropout(0.25)\n",
    "        self.hidden2tag_two = nn.Linear(512, 128)\n",
    "        self.dropout_four = nn.Dropout(0.25)\n",
    "        self.hidden2tag_three = nn.Linear(128, 64)\n",
    "        self.dropout_five = nn.Dropout(0.25)\n",
    "        \n",
    "        self.output = nn.Linear(64, tagset_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        init_embed = self.embedding(input)\n",
    "        #embedded = init_embed.permute(1, 0, 2)\n",
    "        if self.debug == 1:\n",
    "            print(\"Embedding Shape: \", init_embed.shape)\n",
    "        \n",
    "        lstm_out, self.hidden_one = self.lstm_one(init_embed, self.hidden)\n",
    "        lstm_out = self.dropout_one(lstm_out)\n",
    "        lstm_out, self.hidden_two = self.lstm_two(lstm_out, self.hidden)\n",
    "        lstm_out = self.dropout_two(lstm_out)\n",
    "        #\"\"\"\n",
    "        lstm_permute = lstm_out.permute(1, 0, 2)\n",
    "        if self.debug == 1:\n",
    "            print(\"LSTM Out Shape: \", lstm_permute.shape)\n",
    "        \n",
    "        attention = [self.attn_array[i](lstm_permute[i][:]) \\\n",
    "                     for i in range(self.time_steps)]\n",
    "        attention = torch.stack(attention)\n",
    "        attention = attention.permute(1, 0, 2)\n",
    "        if self.debug == 1:\n",
    "            print(\"Attention Shape: \", attention.shape)\n",
    "        \n",
    "        attn_weights = F.softmax(attention, dim=2)\n",
    "        #attn_weights = attn_weights.view(self.minibatch_size, self.time_steps, 1)\n",
    "        if self.debug == 1:\n",
    "            print(\"Softmax Shape: \", attn_weights.shape)\n",
    "        \"\"\"\n",
    "        attn_weights = torch.stack(\n",
    "            [attn_weights]*self.embedding_dim, 2).view(\n",
    "            self.minibatch_size, self.time_steps, -1)\n",
    "        if self.debug == 1:\n",
    "            print(\"Softmax ReShape: \", attn_weights.shape)\n",
    "        \"\"\"\n",
    "        #attn_applied = init_embed\n",
    "        attn_applied = attn_weights * init_embed\n",
    "        #attn_applied = attn_applied.view(self.minibatch_size, self.time_steps, -1)\n",
    "        #attn_applied = torch.sum(attn_applied, dim=1)\n",
    "        if self.debug == 1:\n",
    "            print(\"Embedding*Attention Shape: \", attn_applied.shape)\n",
    "        \n",
    "        #output = F.relu(attn_applied)\n",
    "        #\"\"\"\n",
    "        \n",
    "        lstm_out = attn_applied.contiguous().view(self.minibatch_size, -1)\n",
    "        #lstm_output = lstm_out.contiguous().view(self.minibatch_size, -1)\n",
    "        if self.debug == 1:\n",
    "            print(\"LSTM Output Shape: \", lstm_out.shape)\n",
    "        \n",
    "        \n",
    "        dense_out = self.hidden2tag_one(lstm_out[:])\n",
    "        dense_out = F.relu(dense_out[:])\n",
    "        dense_out = self.dropout_three(dense_out[:])\n",
    "        \n",
    "        dense_out = self.hidden2tag_two(dense_out[:])\n",
    "        dense_out = F.relu(dense_out[:])\n",
    "        dense_out = self.dropout_four(dense_out[:])\n",
    "        \n",
    "        dense_out = self.hidden2tag_three(dense_out[:])\n",
    "        dense_out = F.relu(dense_out[:])\n",
    "        dense_out = self.dropout_five(dense_out[:])\n",
    "        \n",
    "        tag_space = self.output(dense_out[:])\n",
    "        #print(tag_space.shape)\n",
    "        #tag_scores = F.sigmoid(tag_space)\n",
    "        #tag_scores = F.softmax(tag_space, dim=1)\n",
    "        #print(tag_scores.shape)\n",
    "        return tag_space, attn_applied\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, self.minibatch_size, self.hidden_dim),\n",
    "                torch.zeros(1, self.minibatch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(5, 16)\n",
      "  (lstm_one): LSTM(16, 16, batch_first=True)\n",
      "  (dropout_one): Dropout(p=0.25)\n",
      "  (lstm_two): LSTM(16, 16, batch_first=True)\n",
      "  (dropout_two): Dropout(p=0.25)\n",
      "  (hidden2tag_one): Linear(in_features=1616, out_features=512, bias=True)\n",
      "  (dropout_three): Dropout(p=0.25)\n",
      "  (hidden2tag_two): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (dropout_four): Dropout(p=0.25)\n",
      "  (hidden2tag_three): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (dropout_five): Dropout(p=0.25)\n",
      "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AttnDecoderRNN(5, 16, 16)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 101])\n",
      "Embedding Shape:  torch.Size([100, 101, 16])\n",
      "LSTM Out Shape:  torch.Size([101, 100, 16])\n",
      "Attention Shape:  torch.Size([100, 101, 16])\n",
      "Softmax Shape:  torch.Size([100, 101, 16])\n",
      "Embedding*Attention Shape:  torch.Size([100, 101, 16])\n",
      "LSTM Output Shape:  torch.Size([100, 1616])\n",
      "torch.Size([100, 1]) torch.Size([100, 101, 16])\n"
     ]
    }
   ],
   "source": [
    "print(X[:100].shape)\n",
    "with torch.no_grad():\n",
    "    output, attn_weights = model(X[:100])\n",
    "    print(output.shape, attn_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_cross_entropy(output, target, weights=None):\n",
    "        \n",
    "    if weights is not None:\n",
    "        assert len(weights) == 2\n",
    "        \n",
    "        output = torch.clamp(output,min=1e-8,max=1-1e-8) \n",
    "        #loss =  pos_weight * (target * torch.log(output)) + \\\n",
    "        #        neg_weight * ((1 - target) * torch.log(1 - output))\n",
    "        loss = weights[1] * (target * torch.log(output)) + \\\n",
    "               weights[0] * ((1 - target) * torch.log(1 - output))\n",
    "    else:\n",
    "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "\n",
    "    return torch.neg(torch.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(F.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(5, 16)\n",
      "  (lstm_one): LSTM(16, 16, batch_first=True)\n",
      "  (dropout_one): Dropout(p=0.25)\n",
      "  (lstm_two): LSTM(16, 16, batch_first=True)\n",
      "  (dropout_two): Dropout(p=0.25)\n",
      "  (hidden2tag_one): Linear(in_features=1616, out_features=512, bias=True)\n",
      "  (dropout_three): Dropout(p=0.25)\n",
      "  (hidden2tag_two): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (dropout_four): Dropout(p=0.25)\n",
      "  (hidden2tag_three): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (dropout_five): Dropout(p=0.25)\n",
      "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d800af089f0549dcbcb55cf9bbf05bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hirak/miniconda2/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 83.142, Accuracy: 0.798\n",
      "Epoch 2/40, Loss: 44.911, Accuracy: 0.907\n",
      "Epoch 3/40, Loss: 36.505, Accuracy: 0.932\n",
      "Epoch 4/40, Loss: 31.329, Accuracy: 0.935\n",
      "Epoch 5/40, Loss: 23.465, Accuracy: 0.956\n",
      "Epoch 6/40, Loss: 16.480, Accuracy: 0.969\n",
      "Epoch 7/40, Loss: 15.927, Accuracy: 0.971\n",
      "Epoch 8/40, Loss: 8.794, Accuracy: 0.984\n",
      "Epoch 9/40, Loss: 8.798, Accuracy: 0.981\n",
      "Epoch 10/40, Loss: 3.127, Accuracy: 0.993\n",
      "Epoch 11/40, Loss: 5.358, Accuracy: 0.991\n",
      "Epoch 12/40, Loss: 4.445, Accuracy: 0.993\n",
      "Epoch 13/40, Loss: 4.742, Accuracy: 0.991\n",
      "Epoch 14/40, Loss: 3.639, Accuracy: 0.994\n",
      "Epoch 15/40, Loss: 0.582, Accuracy: 0.999\n",
      "Epoch 16/40, Loss: 1.536, Accuracy: 0.998\n",
      "Epoch 17/40, Loss: 1.852, Accuracy: 0.995\n",
      "Epoch 18/40, Loss: 3.896, Accuracy: 0.996\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-51f2e2eabd57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "losses = []\n",
    "accuracies = []\n",
    "#batch_size = 10\n",
    "model = AttnDecoderRNN(5, 16, 16, batch_size=batch_size, debug=0)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "num_epochs = 40\n",
    "for epoch in tqdm(range(num_epochs)):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    \n",
    "    for index in range(0, len(X), batch_size):\n",
    "        sentence = X[index : index+batch_size]#.reshape(len(X[0]))\n",
    "        tags = Y[index : index+batch_size]#.reshape(len(Y[0]))\n",
    "        #print(sentence.shape, tags.shape)\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        # sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        #targets = prepare_sequence(tags, tag_to_ix)\n",
    "        targets = tags.float().flatten()\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores, attn_weight = model(sentence)\n",
    "        tag_scores = tag_scores.flatten()\n",
    "        #print(targets.shape, tag_scores.shape)\n",
    "        \n",
    "        #neg_weight = batch_size / (batch_size-np.sum(data_label[index : index+batch_size]))\n",
    "        #pos_weight = batch_size / np.sum(data_label[index : index+batch_size])\n",
    "        #weights = torch.FloatTensor([neg_weight, pos_weight])\n",
    "        \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = criterion(tag_scores, targets)\n",
    "        #loss = weighted_binary_cross_entropy(tag_scores, targets, weights=weights)\n",
    "        total_loss += loss.data.numpy()\n",
    "        \n",
    "        acc = binary_accuracy(tag_scores, targets)\n",
    "        total_acc += acc\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1,num_epochs, loss.data[0], correct/x.shape[0]))\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    accuracies.append(total_acc/(len(X)/batch_size))\n",
    "    \n",
    "    #total_loss.backward()\n",
    "    #opt.step()\n",
    "    \n",
    "    #print(epoch, total_loss)#, total_acc)\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1,num_epochs, losses[-1], accuracies[-1]))\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuohISCjQRURC4v8DqryLRu6SIxkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14a7679e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKzAOfjOzAuPgNzMrMA5+M7MC8/8BRjpc38BBzNYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14a2facc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Loss\")\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.title(\"Accuracies\")\n",
    "plt.plot(accuracies)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import random, h5py\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#Initialize the Program\n",
    "alphabet = \"NACGT.\"\n",
    "vocab_size = 6\n",
    "batch_size = 1000\n",
    "embedding_size = 4\n",
    "time_steps = 101\n",
    "category = 2\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_complement(sequence):\n",
    "    retseq = ''\n",
    "    for k in range(len(sequence)-1, -1, -1):\n",
    "        if sequence[k] == 'A':\n",
    "            retseq = retseq + 'T'\n",
    "        elif sequence[k] == 'T':\n",
    "            retseq = retseq + 'A'\n",
    "        elif sequence[k] == 'C':\n",
    "            retseq = retseq + 'G'\n",
    "        elif sequence[k] == 'G':\n",
    "            retseq = retseq + 'C'\n",
    "        else:\n",
    "            retseq = retseq + sequence[k]\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Revese:\")\n",
    "    print(sequence)\n",
    "    print(retseq)\n",
    "    print()\n",
    "    \"\"\"\n",
    "    return retseq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Data:\n",
      "200000 526 200000\n",
      "200000 63\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing Data:\")\n",
    "file_read = open(\"../imgtvgene_sequence_classification/mem.txt\")\n",
    "\n",
    "source_sequence = []\n",
    "target_sequence = []\n",
    "\n",
    "max_count = 200000\n",
    "max_source_len = 0\n",
    "\n",
    "vgene_tag = []\n",
    "vgene_dic = {}\n",
    "vgenes = 0\n",
    "\n",
    "count = 0\n",
    "\n",
    "line = file_read.readline()\n",
    "for line in file_read:\n",
    "    split = line.strip().split(\" \")\n",
    "    #print(split)\n",
    "    \n",
    "    try:\n",
    "        source = [char_to_int[x] for x in split[2][1:-1]]\n",
    "        if max_source_len < len(source):\n",
    "            max_source_len = len(source)\n",
    "\n",
    "        seq = [char_to_int[x] for x in split[3][1:-1] if x in \"NACGT\"]\n",
    "        target = [x * int(i < len(seq)) for (i, x) in enumerate(source)]\n",
    "        \n",
    "        assert(len(target) == len(source))\n",
    "    except:\n",
    "        print(\"Exceptions\")\n",
    "        continue\n",
    "        \n",
    "    source_sequence.append(source)\n",
    "    target_sequence.append(target)\n",
    "    \n",
    "    vgene_name = split[-1][1:-1].split(\"*\")[0]\n",
    "    #* for Gene /- for Family /No Split for Allele\n",
    "    if not vgene_name in vgene_dic:\n",
    "        vgene_dic[vgene_name] = vgenes\n",
    "        vgenes += 1\n",
    "    vgene_tag.append(vgene_dic[vgene_name])\n",
    "    \n",
    "    count += 1\n",
    "    #print(split[1], vgene_name)\n",
    "    if count == max_count:\n",
    "        break\n",
    "    \n",
    "print(len(source_sequence), max_source_len, len(target_sequence))\n",
    "print(len(vgene_tag), vgenes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6hgOkqSO4SBJ6hgOkqSO4SBJ6vwXRUxmZNsAbykAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f81239da630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(vgene_tag)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 3, 4, 2, 2, 1, 3, 2, 4, 3, 3, 4, 3, 2, 1, 3, 4, 2, 4, 3,\n",
       "       3, 3, 3, 2, 4, 3, 1, 3, 3, 4, 3, 1, 1, 3, 1, 1, 3, 2, 2, 4, 3, 3,\n",
       "       3, 4, 2, 2, 4, 2, 3, 3, 4, 3, 1, 1, 3, 3, 4, 2, 4, 2, 2, 4, 3, 2,\n",
       "       1, 1, 3, 3, 4, 4, 4, 2, 4, 3, 3, 1, 3, 4, 2, 1, 2, 3, 4, 4, 2, 3,\n",
       "       1, 2, 1, 3, 4, 2, 1, 1, 3, 4, 4, 1, 4, 2, 1, 3, 2, 4, 3, 3, 3, 4,\n",
       "       3, 2, 3, 1, 1, 1, 3, 3, 4, 2, 2, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3,\n",
       "       2, 4, 4, 3, 1, 3, 4, 3, 3, 1, 4, 3, 3, 3, 1, 2, 3, 3, 1, 4, 2, 1,\n",
       "       4, 1, 3, 4, 4, 3, 3, 2, 2, 4, 4, 3, 1, 1, 4, 2, 1, 4, 1, 2, 4, 2,\n",
       "       4, 2, 2, 1, 2, 1, 3, 1, 1, 3, 4, 4, 2, 2, 1, 3, 3, 3, 2, 1, 3, 1,\n",
       "       3, 4, 2, 1, 2, 2, 1, 4, 3, 4, 2, 2, 3, 2, 3, 3, 1, 2, 3, 1, 1, 4,\n",
       "       2, 1, 1, 2, 3, 3, 1, 3, 1, 2, 1, 3, 4, 2, 2, 1, 2, 4, 4, 3, 3, 1,\n",
       "       3, 4, 4, 3, 2, 3, 2, 2, 3, 2, 2, 4, 3, 1, 3, 2, 4, 2, 4, 3, 1, 3,\n",
       "       3, 1, 2, 1, 2, 3, 3, 2, 2, 3, 4, 2, 4, 1, 4, 4, 1, 2, 4, 3, 4, 3,\n",
       "       2, 3, 1, 3, 1, 3, 1, 4, 4, 4, 3, 1, 3, 4, 3, 1, 2, 1, 4, 4, 3, 4,\n",
       "       3, 3, 2, 1, 1, 4, 4, 3, 2, 4, 3, 3, 2, 1, 2, 2, 3, 3, 4, 4, 4, 4,\n",
       "       3, 1, 2, 4, 2, 2, 4, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1, 1, 3, 2, 2,\n",
       "       4, 3, 3, 4, 2, 1, 2, 2, 3, 4, 2, 4, 2, 2, 2, 2, 1, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 3, 4, 2, 2, 1, 3, 2, 4, 3, 3, 4, 3, 2, 1, 3, 4, 2, 4, 3,\n",
       "       3, 3, 3, 2, 4, 3, 1, 3, 3, 4, 3, 1, 1, 3, 1, 1, 3, 2, 2, 4, 3, 3,\n",
       "       3, 4, 2, 2, 4, 2, 3, 3, 4, 3, 1, 1, 3, 3, 4, 2, 4, 2, 2, 4, 3, 2,\n",
       "       1, 1, 3, 3, 4, 4, 4, 2, 4, 3, 3, 1, 3, 4, 2, 1, 2, 3, 4, 4, 2, 3,\n",
       "       1, 2, 1, 3, 4, 2, 1, 1, 3, 4, 4, 1, 4, 2, 1, 3, 2, 4, 3, 3, 3, 4,\n",
       "       3, 2, 3, 1, 1, 1, 3, 3, 4, 2, 2, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3,\n",
       "       2, 4, 4, 3, 1, 3, 4, 3, 3, 1, 4, 3, 3, 3, 1, 2, 3, 3, 1, 4, 2, 1,\n",
       "       4, 1, 3, 4, 4, 3, 3, 2, 2, 4, 4, 3, 1, 1, 4, 2, 1, 4, 1, 2, 4, 2,\n",
       "       4, 2, 2, 1, 2, 1, 3, 1, 1, 3, 4, 4, 2, 2, 1, 3, 3, 3, 2, 1, 3, 1,\n",
       "       3, 4, 2, 1, 2, 2, 1, 4, 3, 4, 2, 2, 3, 2, 3, 3, 1, 2, 3, 1, 1, 4,\n",
       "       2, 1, 1, 2, 3, 3, 1, 3, 1, 2, 1, 3, 4, 2, 2, 1, 2, 4, 4, 3, 3, 1,\n",
       "       3, 4, 4, 3, 2, 3, 2, 2, 3, 2, 2, 4, 3, 1, 3, 2, 4, 2, 4, 3, 1, 3,\n",
       "       3, 1, 2, 1, 2, 3, 3, 2, 2, 3, 4, 2, 4, 1, 4, 4, 1, 2, 4, 3, 4, 3,\n",
       "       2, 3, 1, 3, 1, 3, 1, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 200000 200000\n",
      "(200000, 526) (200000, 63) (200000, 526)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "source_data = pad_sequences(source_sequence, maxlen=max_source_len, padding='post', value=0)\n",
    "classes = to_categorical(vgene_tag)\n",
    "target_data = pad_sequences(target_sequence, maxlen=max_source_len, padding='post', value=0)\n",
    "\n",
    "print(len(source_sequence), len(vgene_tag), len(target_sequence))\n",
    "print(source_data.shape, classes.shape, target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 3, 4, 2, 1, 2, 2, 4, 4, 3, 1, 1, 3, 3, 1, 3, 4, 2, 4, 3,\n",
       "       3, 4, 2, 2, 4, 3, 4, 3, 2, 4, 3, 3, 4, 3, 1, 1, 1, 2, 2, 2, 1, 1,\n",
       "       1, 2, 1, 3, 1, 2, 2, 2, 4, 2, 1, 2, 3, 2, 4, 3, 1, 2, 2, 4, 3, 2,\n",
       "       1, 2, 2, 4, 4, 2, 4, 2, 4, 2, 1, 1, 2, 4, 2, 4, 2, 1, 4, 4, 2, 4,\n",
       "       2, 2, 1, 1, 4, 2, 2, 4, 1, 3, 1, 4, 4, 3, 3, 3, 4, 3, 4, 2, 1, 3,\n",
       "       2, 4, 3, 3, 1, 4, 2, 2, 3, 4, 2, 1, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3,\n",
       "       1, 1, 3, 3, 2, 2, 2, 4, 3, 3, 1, 3, 4, 3, 3, 2, 4, 4, 3, 2, 1, 2,\n",
       "       1, 2, 1, 4, 4, 4, 4, 4, 4, 2, 3, 1, 1, 4, 3, 1, 2, 3, 1, 3, 1, 1,\n",
       "       1, 4, 2, 2, 4, 1, 2, 1, 3, 2, 1, 2, 1, 4, 2, 4, 2, 4, 3, 1, 3, 3,\n",
       "       1, 3, 2, 1, 3, 3, 2, 4, 2, 1, 2, 2, 1, 4, 2, 4, 2, 2, 1, 1, 3, 3,\n",
       "       1, 2, 1, 2, 2, 4, 2, 4, 1, 1, 1, 1, 3, 2, 2, 1, 3, 3, 4, 3, 3, 4,\n",
       "       2, 2, 4, 3, 1, 2, 2, 2, 4, 3, 1, 2, 2, 1, 1, 4, 3, 4, 3, 3, 3, 2,\n",
       "       2, 2, 4, 3, 4, 3, 3, 1, 2, 1, 2, 1, 3, 2, 2, 1, 2, 1, 4, 1, 4, 4,\n",
       "       1, 2, 4, 3, 4, 3, 2, 1, 4, 3, 3, 3, 3, 3, 4, 2, 4, 3, 4, 2, 2, 2,\n",
       "       1, 3, 4, 4, 1, 1, 4, 3, 3, 3, 4, 1, 2, 4, 1, 2, 4, 1, 2, 4, 1, 2,\n",
       "       4, 1, 2, 1, 4, 3, 3, 1, 2, 3, 4, 2, 4, 3, 3, 3, 3, 2, 1, 1, 1, 3,\n",
       "       3, 3, 1, 2, 2, 3, 2, 3, 3, 4, 2, 1, 2, 2, 3, 4, 2, 4, 2, 3, 4, 2,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 3, 4, 2, 1, 2, 2, 4, 4, 3, 1, 1, 3, 3, 1, 3, 4, 2, 4, 3,\n",
       "       3, 4, 2, 2, 4, 3, 4, 3, 2, 4, 3, 3, 4, 3, 1, 1, 1, 2, 2, 2, 1, 1,\n",
       "       1, 2, 1, 3, 1, 2, 2, 2, 4, 2, 1, 2, 3, 2, 4, 3, 1, 2, 2, 4, 3, 2,\n",
       "       1, 2, 2, 4, 4, 2, 4, 2, 4, 2, 1, 1, 2, 4, 2, 4, 2, 1, 4, 4, 2, 4,\n",
       "       2, 2, 1, 1, 4, 2, 2, 4, 1, 3, 1, 4, 4, 3, 3, 3, 4, 3, 4, 2, 1, 3,\n",
       "       2, 4, 3, 3, 1, 4, 2, 2, 3, 4, 2, 1, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3,\n",
       "       1, 1, 3, 3, 2, 2, 2, 4, 3, 3, 1, 3, 4, 3, 3, 2, 4, 4, 3, 2, 1, 2,\n",
       "       1, 2, 1, 4, 4, 4, 4, 4, 4, 2, 3, 1, 1, 4, 3, 1, 2, 3, 1, 3, 1, 1,\n",
       "       1, 4, 2, 2, 4, 1, 2, 1, 3, 2, 1, 2, 1, 4, 2, 4, 2, 4, 3, 1, 3, 3,\n",
       "       1, 3, 2, 1, 3, 3, 2, 4, 2, 1, 2, 2, 1, 4, 2, 4, 2, 2, 1, 1, 3, 3,\n",
       "       1, 2, 1, 2, 2, 4, 2, 4, 1, 1, 1, 1, 3, 2, 2, 1, 3, 3, 4, 3, 3, 4,\n",
       "       2, 2, 4, 3, 1, 2, 2, 2, 4, 3, 1, 2, 2, 1, 1, 4, 3, 4, 3, 3, 3, 2,\n",
       "       2, 2, 4, 3, 4, 3, 3, 1, 2, 1, 2, 1, 3, 2, 2, 1, 2, 1, 4, 1, 4, 4,\n",
       "       1, 2, 4, 3, 4, 3, 2, 1, 4, 3, 3, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(sequence, n_unique):\n",
    "    encoding = np.zeros((len(sequence), n_unique))\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        encoding[i][sequence[i]] = 1\n",
    "    \n",
    "    return encoding\n",
    "\n",
    "print(max(source_data[0]), max(target_data[0]))\n",
    "print(one_hot_encode(source_data[0], vocab_size))\n",
    "print(one_hot_encode(target_data[0], vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 526, 5)\n"
     ]
    }
   ],
   "source": [
    "source_encoded = np.array([one_hot_encode(seq, vocab_size-1) for seq in source_data[:]])\n",
    "print(source_encoded.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 526, 5)\n"
     ]
    }
   ],
   "source": [
    "target_encoded = np.array([one_hot_encode(seq, vocab_size-1) for seq in target_data[:]])\n",
    "print(target_encoded.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000.0 200000\n"
     ]
    }
   ],
   "source": [
    "print(sum(sum(classes[:])), len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the encoder-decoder model\n",
    "def baseline_model(n_timesteps_in, n_features, n_classes):\n",
    "    model = Sequential()\n",
    "    #model.add(LSTM(5, input_shape=(n_timesteps_in, n_features), return_sequences=True))\n",
    "    #model.add(LSTM(150, return_sequences=True))\n",
    "    model.add(Flatten(input_shape=(n_timesteps_in, n_features)))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 2630)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2630)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2694144   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 63)                16191     \n",
      "=================================================================\n",
      "Total params: 3,366,463\n",
      "Trainable params: 3,366,463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/3\n",
      " - 58s - loss: 0.2989 - acc: 0.9123 - val_loss: 0.1996 - val_acc: 0.9246\n",
      "Epoch 2/3\n",
      " - 58s - loss: 0.1013 - acc: 0.9694 - val_loss: 0.1044 - val_acc: 0.9658\n",
      "Epoch 3/3\n",
      " - 58s - loss: 0.0866 - acc: 0.9742 - val_loss: 0.1817 - val_acc: 0.9459\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f811852e6d8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "from custom_recurrents import AttentionDecoder\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "print('Train...')\n",
    "\n",
    "train_data_size = 100000\n",
    "test_source_len = max_source_len\n",
    "model = baseline_model(test_source_len, vocab_size-1, len(classes[0]))\n",
    "\n",
    "model.fit(target_encoded[:train_data_size, :test_source_len, :], \\\n",
    "          classes[:train_data_size], callbacks=[TQDMNotebookCallback()], \\\n",
    "          validation_data=(source_encoded[train_data_size:, :test_source_len, :], \\\n",
    "          classes[train_data_size:]), batch_size=100, epochs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_LEN = max_source_len # maximum sequence length\n",
    "DIM_ENC = 5 # dimension of a one-hot encoded vector (e.g., 4 (sequence) x 4 (structure) = 16)\n",
    "DIM_LSTM1 = 16\n",
    "DIM_LSTM2 = 16\n",
    "DIM_DENSE1 = 256\n",
    "DMI_DENSE2 = 128\n",
    "N_CLASSES = len(classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Reshape, Dense\n",
    "from keras.models import Model\n",
    "from deepMiRGene import SoftAttention\n",
    "\n",
    "# define the encoder-decoder with attention model\n",
    "def attention_model(MAX_LEN, N_CLASSES, DIM_ENC=5, \\\n",
    "                    DIM_LSTM1=16, DIM_LSTM2=16, \\\n",
    "                    DIM_DENSE1=256, DMI_DENSE2=128):\n",
    "    \n",
    "    inputs = Input(shape=(MAX_LEN,DIM_ENC), name='inputs')\n",
    "    msk = Masking(mask_value=0)(inputs)\n",
    "    lstm1 = LSTM(DIM_LSTM1, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(msk)\n",
    "    lstm2 = LSTM(DIM_LSTM2, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(lstm1)\n",
    "\n",
    "    att, pv = SoftAttention(lstm2)(lstm2)\n",
    "\n",
    "    do1 = Dropout(0.1)(att)\n",
    "    dense1 = Dense(DIM_DENSE1,activation='sigmoid')(do1)\n",
    "    do2 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(DMI_DENSE2,activation='sigmoid')(do2)\n",
    "    outputs = Dense(N_CLASSES,activation='softmax')(dense2)\n",
    "\n",
    "    model=Model(outputs=outputs, inputs=inputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Mask:  Tensor(\"masking_1/Any_1:0\", shape=(?, 526), dtype=bool)\n",
      "Cast:  Tensor(\"soft_attention_1/Cast:0\", shape=(?, 526), dtype=float32)\n",
      "Return PT\n",
      "Vector:  Tensor(\"soft_attention_1/mul_1:0\", shape=(?, 526), dtype=float32)\n",
      "Vector:  Tensor(\"soft_attention_1/ExpandDims:0\", shape=(?, 526, 1), dtype=float32)\n",
      "Object:  Tensor(\"lstm_2/transpose_2:0\", shape=(?, ?, 16), dtype=float32) (None, 526, 16)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 526, 5)            0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 526, 5)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 526, 16)           1408      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 526, 16)           2112      \n",
      "_________________________________________________________________\n",
      "soft_attention_1 (SoftAttent [(None, 8416), (None, 526 17        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8416)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               2154752   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 63)                8127      \n",
      "=================================================================\n",
      "Total params: 2,199,312\n",
      "Trainable params: 2,199,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/10\n",
      " - 1444s - loss: 2.1290 - acc: 0.4154 - val_loss: 1.2328 - val_acc: 0.6489\n",
      "Epoch 2/10\n",
      " - 1436s - loss: 0.9676 - acc: 0.7059 - val_loss: 0.7260 - val_acc: 0.7689\n",
      "Epoch 3/10\n",
      " - 1433s - loss: 0.6238 - acc: 0.8033 - val_loss: 0.5303 - val_acc: 0.8331\n",
      "Epoch 4/10\n",
      " - 1441s - loss: 0.4320 - acc: 0.8658 - val_loss: 0.3873 - val_acc: 0.8878\n",
      "Epoch 5/10\n",
      " - 1453s - loss: 0.3132 - acc: 0.9031 - val_loss: 0.3292 - val_acc: 0.9030\n",
      "Epoch 6/10\n",
      " - 1536s - loss: 0.2422 - acc: 0.9254 - val_loss: 0.2820 - val_acc: 0.9196\n",
      "Epoch 7/10\n",
      " - 1483s - loss: 0.1951 - acc: 0.9424 - val_loss: 0.2650 - val_acc: 0.9195\n",
      "Epoch 8/10\n",
      " - 1499s - loss: 0.1613 - acc: 0.9531 - val_loss: 0.2383 - val_acc: 0.9321\n",
      "Epoch 9/10\n",
      " - 1519s - loss: 0.1373 - acc: 0.9599 - val_loss: 0.2294 - val_acc: 0.9324\n",
      "Epoch 10/10\n",
      " - 1612s - loss: 0.1197 - acc: 0.9654 - val_loss: 0.2165 - val_acc: 0.9395\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7dd0775d68>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "from custom_recurrents import AttentionDecoder\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "print('Train...')\n",
    "\n",
    "train_data_size = 100000\n",
    "test_source_len = max_source_len\n",
    "model = attention_model(MAX_LEN, N_CLASSES)\n",
    "\n",
    "model.fit(target_encoded[:train_data_size, :test_source_len, :], \\\n",
    "          classes[:train_data_size], callbacks=[TQDMNotebookCallback()], \\\n",
    "          validation_data=(source_encoded[train_data_size:, :test_source_len, :], \\\n",
    "          classes[train_data_size:]), batch_size=100, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Mask:  Tensor(\"masking_2/Any_1:0\", shape=(?, 526), dtype=bool)\n",
      "Cast:  Tensor(\"soft_attention_2/Cast:0\", shape=(?, 526), dtype=float32)\n",
      "Return PT\n",
      "Vector:  Tensor(\"soft_attention_2/mul_1:0\", shape=(?, 526), dtype=float32)\n",
      "Vector:  Tensor(\"soft_attention_2/ExpandDims:0\", shape=(?, 526, 1), dtype=float32)\n",
      "Object:  Tensor(\"lstm_4/transpose_2:0\", shape=(?, ?, 16), dtype=float32) (None, 526, 16)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 526, 5)            0         \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, 526, 5)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 526, 16)           1408      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 526, 16)           2112      \n",
      "_________________________________________________________________\n",
      "soft_attention_2 (SoftAttent [(None, 8416), (None, 526 17        \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8416)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               2154752   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 63)                8127      \n",
      "=================================================================\n",
      "Total params: 2,199,312\n",
      "Trainable params: 2,199,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/10\n",
      " - 1589s - loss: 2.1544 - acc: 0.3934 - val_loss: 1.3098 - val_acc: 0.6021\n",
      "Epoch 2/10\n",
      " - 1536s - loss: 1.0358 - acc: 0.6902 - val_loss: 0.8377 - val_acc: 0.7337\n",
      "Epoch 3/10\n",
      " - 1525s - loss: 0.6486 - acc: 0.7972 - val_loss: 0.6082 - val_acc: 0.8100\n",
      "Epoch 4/10\n",
      " - 1476s - loss: 0.4670 - acc: 0.8558 - val_loss: 0.5173 - val_acc: 0.8402\n",
      "Epoch 5/10\n",
      " - 1449s - loss: 0.3599 - acc: 0.8881 - val_loss: 0.4568 - val_acc: 0.8605\n",
      "Epoch 6/10\n",
      " - 1403s - loss: 0.2969 - acc: 0.9083 - val_loss: 0.3969 - val_acc: 0.8759\n",
      "Epoch 7/10\n",
      " - 1400s - loss: 0.2517 - acc: 0.9228 - val_loss: 0.3598 - val_acc: 0.8892\n",
      "Epoch 8/10\n",
      " - 1412s - loss: 0.2141 - acc: 0.9357 - val_loss: 0.3179 - val_acc: 0.9032\n",
      "Epoch 9/10\n",
      " - 1396s - loss: 0.1887 - acc: 0.9432 - val_loss: 0.3234 - val_acc: 0.8957\n",
      "Epoch 10/10\n",
      " - 1399s - loss: 0.1679 - acc: 0.9496 - val_loss: 0.2904 - val_acc: 0.9089\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c5866b080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "from custom_recurrents import AttentionDecoder\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "print('Train...')\n",
    "\n",
    "train_data_size = 100000\n",
    "test_source_len = max_source_len\n",
    "nodel = attention_model(MAX_LEN, N_CLASSES)\n",
    "\n",
    "nodel.fit(target_encoded[:train_data_size, :test_source_len, :], \\\n",
    "          classes[:train_data_size], callbacks=[TQDMNotebookCallback()], \\\n",
    "          validation_data=(source_encoded[train_data_size:, :test_source_len, :], \\\n",
    "          classes[train_data_size:]), batch_size=100, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "8499a63c49664f7da2ae0bc62400f410": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "9fe621d9c11545fa938e440387d778de": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "a367a88458ea40b0af40909287a414f0": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "ef6cc56e921941a6aea2ae87d1effd3a": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "f8ea7094fc6c4fc18831f2bf0608734b": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

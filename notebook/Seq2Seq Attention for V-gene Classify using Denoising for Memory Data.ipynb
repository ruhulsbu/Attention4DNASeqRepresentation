{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import random, h5py\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#Initialize the Program\n",
    "alphabet = \"NACGT.\"\n",
    "vocab_size = 6\n",
    "batch_size = 1000\n",
    "embedding_size = 4\n",
    "time_steps = 101\n",
    "category = 2\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_complement(sequence):\n",
    "    retseq = ''\n",
    "    for k in range(len(sequence)-1, -1, -1):\n",
    "        if sequence[k] == 'A':\n",
    "            retseq = retseq + 'T'\n",
    "        elif sequence[k] == 'T':\n",
    "            retseq = retseq + 'A'\n",
    "        elif sequence[k] == 'C':\n",
    "            retseq = retseq + 'G'\n",
    "        elif sequence[k] == 'G':\n",
    "            retseq = retseq + 'C'\n",
    "        else:\n",
    "            retseq = retseq + sequence[k]\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Revese:\")\n",
    "    print(sequence)\n",
    "    print(retseq)\n",
    "    print()\n",
    "    \"\"\"\n",
    "    return retseq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\nsource_sequence = np.array(source_sequence)\\ntarget_sequence = np.array(target_sequence)\\n\\ncluster_tag = np.array(cluster_tag)\\nvgene_tag = np.array(vgene_tag)\\n\\nprint(source_sequence.shape, target_sequence.shape)\\nprint(max_source, max_target)\\nprint()\\nprint(cluster_tag.shape, vgene_tag.shape)\\nprint(classes, vgenes)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_read = open(\"../imgtvgene_sequence_classification/mem.txt\")\n",
    "\n",
    "source_sequence = []\n",
    "target_sequence = []\n",
    "\n",
    "cluster_tag = []\n",
    "cluster_dic = {}\n",
    "classes = 0\n",
    "\n",
    "vgene_tag = []\n",
    "vgene_dic = {}\n",
    "vgenes = 0\n",
    "\n",
    "count = 0\n",
    "max_count = 200000\n",
    "\n",
    "max_source = 0\n",
    "max_target = 0\n",
    "\n",
    "line = file_read.readline()\n",
    "for line in file_read:\n",
    "    split = line.strip().split(\" \")\n",
    "    #print(split)\n",
    "    \n",
    "    if not split[1] in cluster_dic:\n",
    "        classes += 1\n",
    "        cluster_dic[split[1]] = classes\n",
    "    cluster_tag.append(split[1])\n",
    "    \n",
    "    source = [char_to_int[x] for x in split[2][1:-1]]\n",
    "    source_sequence.append(source)\n",
    "    if max_source < len(source):\n",
    "        max_source = len(source)\n",
    "    \n",
    "    target = [char_to_int[x] for x in split[-2][1:-1]]\n",
    "    target_sequence.append(target)\n",
    "    if max_target < len(target):\n",
    "        max_target = len(target)\n",
    "    \n",
    "    #vgene_name = split[-1][1:-1]#.split(\"*\")[0]\n",
    "    vgene_name = split[-1][1:-1].split(\"*\")[0]\n",
    "    \n",
    "    if not vgene_name in vgene_dic:\n",
    "        vgene_dic[vgene_name] = vgenes\n",
    "        vgenes += 1\n",
    "    vgene_tag.append(vgene_dic[vgene_name])\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    #print(split[1], vgene_name)\n",
    "    if count == max_count:\n",
    "        break\n",
    "\"\"\"    \n",
    "source_sequence = np.array(source_sequence)\n",
    "target_sequence = np.array(target_sequence)\n",
    "\n",
    "cluster_tag = np.array(cluster_tag)\n",
    "vgene_tag = np.array(vgene_tag)\n",
    "\n",
    "print(source_sequence.shape, target_sequence.shape)\n",
    "print(max_source, max_target)\n",
    "print()\n",
    "print(cluster_tag.shape, vgene_tag.shape)\n",
    "print(classes, vgenes)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6hgOkqSO4SBJ6hgOkqSO4SBJ6vwXRUxmZNsAbykAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f3136c0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526 207 62\n",
      "200000 200000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(vgene_tag)\n",
    "plt.show()\n",
    "\n",
    "print(max_source, max_target, max(vgene_tag))\n",
    "print(len(source_sequence), len(target_sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Positive and Negative Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, max_count):\n",
    "    randomized = np.random.randint(0, 5, size=len(source_sequence[i]))\n",
    "    source_sequence.append(randomized)\n",
    "    target_sequence.append(target_sequence[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 526) (400000, 263)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_source_len = 526\n",
    "max_target_len = int(max_source_len/2)\n",
    "\n",
    "source_sequence = pad_sequences(source_sequence, maxlen=max_source_len, value=0)\n",
    "target_sequence = pad_sequences(target_sequence, maxlen=max_target_len, value=0)\n",
    "\n",
    "print(source_sequence.shape, target_sequence.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000,) 200000\n"
     ]
    }
   ],
   "source": [
    "shared_data_label = []\n",
    "for i in range(len(source_sequence)):\n",
    "    if i < int(len(source_sequence)/2):\n",
    "        shared_data_label.append(1)\n",
    "    else:\n",
    "        shared_data_label.append(0)\n",
    "shared_data_label = np.array(shared_data_label)\n",
    "print(shared_data_label.shape, np.count_nonzero(shared_data_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Denoising Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_source (InputLayer)       (None, 526)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           multiple             24          input_source[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_two_source (LSTM)          (None, 128)          68096       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_two_target (LSTM)          (None, 128)          68096       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 128)          0           lstm_two_source[0][0]            \n",
      "                                                                 lstm_two_target[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "logistic (Dense)                (None, 1)            129         multiply_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 136,345\n",
      "Trainable params: 136,345\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import UpSampling1D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "input_source = Input(shape=(max_source_len,), dtype='int32', name='input_source')\n",
    "input_target = Input(shape=(max_target_len,), dtype='int32', name='input_target')\n",
    "#batch_shape=(batch_size, time_steps), \n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_size, \\\n",
    "                            name=\"embedding\")\n",
    "embed_source = embedding_layer(input_source)\n",
    "\n",
    "#embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_size, \\\n",
    "#                            name=\"embedding\")\n",
    "embed_target = embedding_layer(input_target)\n",
    "\n",
    "lstm_layer_source_one = LSTM(units=128, stateful=False, \\\n",
    "                            return_sequences=True, unroll=False, name=\"lstm_one_source\")\n",
    "lstm_one_source = lstm_layer_source_one(embed_source)\n",
    "\n",
    "lstm_layer_target_one = LSTM(units=128, stateful=False, \\\n",
    "                            return_sequences=True, unroll=False, name=\"lstm_one_target\")\n",
    "lstm_one_target = lstm_layer_target_one(embed_target)\n",
    "\n",
    "\n",
    "lstm_layer_source_two = LSTM(units=128, stateful=False, \\\n",
    "                            return_sequences=False, unroll=False, name=\"lstm_two_source\")\n",
    "lstm_two_source = lstm_layer_source_two(embed_source)#(lstm_one_source)\n",
    "\n",
    "lstm_layer_target_two = LSTM(units=128, stateful=False, \\\n",
    "                            return_sequences=False, unroll=False, name=\"lstm_two_target\")\n",
    "lstm_two_target = lstm_layer_target_two(embed_source)#(lstm_one_target)\n",
    "\n",
    "\n",
    "element_wise_product = keras.layers.Multiply()([lstm_two_source, lstm_two_target])\n",
    "dot_product = keras.layers.Dot(axes=1, normalize=True)([lstm_two_source, lstm_two_target])\n",
    "\n",
    "# And add a logistic regression on top\n",
    "predictions = Dense(1, activation='sigmoid', name=\"logistic\")(element_wise_product)\n",
    "\n",
    "# We define a trainable model linking the\n",
    "# tweet inputs to the predictions\n",
    "shared_model = Model(inputs=[input_source, input_target], outputs=predictions)\n",
    "\n",
    "shared_model.compile(optimizer=\"adam\", #optimizer='sgd',\n",
    "              loss=\"binary_crossentropy\", #loss='mean_squared_error',\n",
    "              metrics=['acc'])\n",
    "shared_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(shared_model, to_file=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/1\n",
      " - 2214s - loss: 0.3161 - acc: 0.8265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "print('Train...')\n",
    "history = shared_model.fit([source_sequence, target_sequence], shared_data_label, \n",
    "        batch_size=batch_size*1, shuffle=True, epochs=1, verbose=2,\n",
    "        callbacks=[TQDMNotebookCallback()])#, validation_data=(x_eval, y_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nThS7zQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9424371128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Encoded Squence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 526\n",
      "200000 63\n"
     ]
    }
   ],
   "source": [
    "file_read = open(\"../imgtvgene_sequence_classification/mem.txt\")\n",
    "\n",
    "source_sequence = []\n",
    "max_count = 200000\n",
    "max_source_len = 0\n",
    "\n",
    "vgene_tag = []\n",
    "vgene_dic = {}\n",
    "vgenes = 0\n",
    "\n",
    "count = 0\n",
    "\n",
    "line = file_read.readline()\n",
    "for line in file_read:\n",
    "    split = line.strip().split(\" \")\n",
    "    #print(split)\n",
    "    \n",
    "    source = [char_to_int[x] for x in split[2][1:-1]]\n",
    "    source_sequence.append(source)\n",
    "    if max_source_len < len(source):\n",
    "        max_source_len = len(source)\n",
    "    \n",
    "    vgene_name = split[-1][1:-1].split(\"*\")[0]\n",
    "    #* for Gene /- for Family /No Split for Allele\n",
    "    if not vgene_name in vgene_dic:\n",
    "        vgene_dic[vgene_name] = vgenes\n",
    "        vgenes += 1\n",
    "    vgene_tag.append(vgene_dic[vgene_name])\n",
    "    \n",
    "    count += 1\n",
    "    #print(split[1], vgene_name)\n",
    "    if count == max_count:\n",
    "        break\n",
    "    \n",
    "print(len(source_sequence), max_source_len)\n",
    "print(len(vgene_tag), vgenes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 526) (200000, 63) (200000, 263)\n"
     ]
    }
   ],
   "source": [
    "x_data = pad_sequences(source_sequence, maxlen=max_source_len, value=0)\n",
    "y_data = to_categorical(vgene_tag)\n",
    "zeros = np.zeros((len(x_data), int(len(x_data[0])/2)))\n",
    "\n",
    "print(x_data.shape, y_data.shape, zeros.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layer_name = \"lstm_two_source\"\n",
    "intermediate_layer_model = Model(inputs=shared_model.input,\n",
    "                                 outputs=shared_model.get_layer(layer_name).get_output_at(0))\n",
    "intermediate_output = intermediate_layer_model.predict([x_data, zeros])\n",
    "\n",
    "print(intermediate_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classifying Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, eval, test =  (160000, 200000, 240000)\n",
      "(160000, 128) (160000, 63)\n",
      "(40000, 128) (40000, 63)\n",
      "(0, 128) (0, 63)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_index = int((len(x_data) / batch_size) * 0.80 * batch_size)\n",
    "eval_index = train_index + int((len(x_data) / batch_size) * 0.20 * batch_size)\n",
    "test_index = eval_index + int((len(x_data) / batch_size) * 0.20 * batch_size)\n",
    "print(\"train, eval, test = \", (train_index, eval_index, test_index))\n",
    "\n",
    "x_train = intermediate_output[0:train_index]\n",
    "y_train = y_data[0:train_index]\n",
    "\n",
    "x_eval = intermediate_output[train_index:eval_index]\n",
    "y_eval = y_data[train_index:eval_index]\n",
    "\n",
    "x_test = intermediate_output[eval_index:test_index]\n",
    "y_test = y_data[eval_index:test_index]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_eval.shape, y_eval.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 526)               0         \n",
      "_________________________________________________________________\n",
      "fstlayer (Dense)             (None, 2048)              1079296   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "midlayer1 (Dense)            (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "midlayer2 (Dense)            (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "finlayer (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 63)                16191     \n",
      "=================================================================\n",
      "Total params: 3,849,791\n",
      "Trainable params: 3,849,791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import Reshape, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "input_source = Input(shape=(max_source_len,), \\\n",
    "                     dtype='float32', name='main_input')\n",
    "\n",
    "dense_layer_first = Dense(2048, activation='relu', \\\n",
    "                        name='fstlayer')(input_source)\n",
    "dense_layer_first = Dropout(0.25)(dense_layer_first)\n",
    "\n",
    "dense_layer_mid = Dense(1024, activation='relu', \\\n",
    "                        name='midlayer1')(dense_layer_first)\n",
    "dense_layer_mid = Dropout(0.25)(dense_layer_mid)\n",
    "\n",
    "dense_layer_mid = Dense(512, activation='relu', \\\n",
    "                        name='midlayer2')(dense_layer_mid)\n",
    "dense_layer_mid = Dropout(0.25)(dense_layer_mid)\n",
    "\n",
    "dense_layer = Dense(256, activation='relu', \\\n",
    "                    name='finlayer')(dense_layer_mid)\n",
    "dense_layer = Dropout(0.25)(dense_layer)\n",
    "\n",
    "dense_output = Dense(vgenes, activation='softmax', \\\n",
    "                     name='output')(dense_layer)\n",
    "\n",
    "classify_model = Model(inputs=[input_source], outputs=[dense_output])\n",
    "classify_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classify_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/200\n",
      " - 25s - loss: 2.9384 - acc: 0.2206\n",
      "Epoch 2/200\n",
      " - 24s - loss: 1.4070 - acc: 0.5492\n",
      "Epoch 3/200\n",
      " - 24s - loss: 0.9796 - acc: 0.6727\n",
      "Epoch 4/200\n",
      " - 25s - loss: 0.8287 - acc: 0.7232\n",
      "Epoch 5/200\n",
      " - 24s - loss: 0.7331 - acc: 0.7544\n",
      "Epoch 6/200\n",
      " - 24s - loss: 0.6833 - acc: 0.7720\n",
      "Epoch 7/200\n",
      " - 24s - loss: 0.6481 - acc: 0.7845\n",
      "Epoch 8/200\n",
      " - 26s - loss: 0.6204 - acc: 0.7941\n",
      "Epoch 9/200\n",
      " - 27s - loss: 0.6063 - acc: 0.7988\n",
      "Epoch 10/200\n",
      " - 25s - loss: 0.5914 - acc: 0.8032\n",
      "Epoch 11/200\n",
      " - 25s - loss: 0.5708 - acc: 0.8098\n",
      "Epoch 12/200\n",
      " - 25s - loss: 0.5578 - acc: 0.8143\n",
      "Epoch 13/200\n",
      " - 28s - loss: 0.5424 - acc: 0.8201\n",
      "Epoch 14/200\n",
      " - 26s - loss: 0.5375 - acc: 0.8225\n",
      "Epoch 15/200\n",
      " - 25s - loss: 0.5300 - acc: 0.8232\n",
      "Epoch 16/200\n",
      " - 25s - loss: 0.5290 - acc: 0.8246\n",
      "Epoch 17/200\n",
      " - 25s - loss: 0.5116 - acc: 0.8308\n",
      "Epoch 18/200\n",
      " - 26s - loss: 0.5055 - acc: 0.8331\n",
      "Epoch 19/200\n",
      " - 25s - loss: 0.5002 - acc: 0.8339\n",
      "Epoch 20/200\n",
      " - 24s - loss: 0.4837 - acc: 0.8392\n",
      "Epoch 21/200\n",
      " - 26s - loss: 0.4762 - acc: 0.8416\n",
      "Epoch 22/200\n",
      " - 26s - loss: 0.4682 - acc: 0.8440\n",
      "Epoch 23/200\n",
      " - 25s - loss: 0.4596 - acc: 0.8483\n",
      "Epoch 24/200\n",
      " - 26s - loss: 0.4473 - acc: 0.8499\n",
      "Epoch 25/200\n",
      " - 26s - loss: 0.4334 - acc: 0.8551\n",
      "Epoch 26/200\n",
      " - 27s - loss: 0.4373 - acc: 0.8545\n",
      "Epoch 27/200\n",
      " - 26s - loss: 0.4348 - acc: 0.8547\n",
      "Epoch 28/200\n",
      " - 25s - loss: 0.4377 - acc: 0.8545\n",
      "Epoch 29/200\n",
      " - 25s - loss: 0.4296 - acc: 0.8570\n",
      "Epoch 30/200\n",
      " - 25s - loss: 0.4244 - acc: 0.8586\n",
      "Epoch 31/200\n",
      " - 26s - loss: 0.4147 - acc: 0.8620\n",
      "Epoch 32/200\n",
      " - 25s - loss: 0.4045 - acc: 0.8650\n",
      "Epoch 33/200\n",
      " - 25s - loss: 0.4065 - acc: 0.8644\n",
      "Epoch 34/200\n",
      " - 27s - loss: 0.4037 - acc: 0.8651\n",
      "Epoch 35/200\n",
      " - 25s - loss: 0.3940 - acc: 0.8680\n",
      "Epoch 36/200\n",
      " - 25s - loss: 0.3948 - acc: 0.8680\n",
      "Epoch 37/200\n",
      " - 26s - loss: 0.3889 - acc: 0.8697\n",
      "Epoch 38/200\n",
      " - 25s - loss: 0.3929 - acc: 0.8688\n",
      "Epoch 39/200\n",
      " - 26s - loss: 0.3898 - acc: 0.8708\n",
      "Epoch 40/200\n",
      " - 25s - loss: 0.3877 - acc: 0.8703\n",
      "Epoch 41/200\n",
      " - 27s - loss: 0.3862 - acc: 0.8716\n",
      "Epoch 42/200\n",
      " - 26s - loss: 0.3883 - acc: 0.8710\n",
      "Epoch 43/200\n",
      " - 26s - loss: 0.3815 - acc: 0.8721\n",
      "Epoch 44/200\n",
      " - 36s - loss: 0.3791 - acc: 0.8728\n",
      "Epoch 45/200\n",
      " - 25s - loss: 0.3839 - acc: 0.8731\n",
      "Epoch 46/200\n",
      " - 25s - loss: 0.3748 - acc: 0.8752\n",
      "Epoch 47/200\n",
      " - 26s - loss: 0.3688 - acc: 0.8775\n",
      "Epoch 48/200\n",
      " - 27s - loss: 0.3574 - acc: 0.8806\n",
      "Epoch 49/200\n",
      " - 26s - loss: 0.3601 - acc: 0.8798\n",
      "Epoch 50/200\n",
      " - 34s - loss: 0.3608 - acc: 0.8802\n",
      "Epoch 51/200\n",
      " - 27s - loss: 0.3589 - acc: 0.8807\n",
      "Epoch 52/200\n",
      " - 25s - loss: 0.3590 - acc: 0.8803\n",
      "Epoch 53/200\n",
      " - 26s - loss: 0.3556 - acc: 0.8815\n",
      "Epoch 54/200\n",
      " - 26s - loss: 0.3520 - acc: 0.8829\n",
      "Epoch 55/200\n",
      " - 25s - loss: 0.3439 - acc: 0.8844\n",
      "Epoch 56/200\n",
      " - 35s - loss: 0.3493 - acc: 0.8842\n",
      "Epoch 57/200\n",
      " - 27s - loss: 0.3486 - acc: 0.8838\n",
      "Epoch 58/200\n",
      " - 25s - loss: 0.3392 - acc: 0.8864\n",
      "Epoch 59/200\n",
      " - 25s - loss: 0.3444 - acc: 0.8853\n",
      "Epoch 60/200\n",
      " - 26s - loss: 0.3422 - acc: 0.8856\n",
      "Epoch 61/200\n",
      " - 26s - loss: 0.3329 - acc: 0.8883\n",
      "Epoch 62/200\n",
      " - 33s - loss: 0.3337 - acc: 0.8879\n",
      "Epoch 63/200\n",
      " - 29s - loss: 0.3349 - acc: 0.8887\n",
      "Epoch 64/200\n",
      " - 25s - loss: 0.3378 - acc: 0.8879\n",
      "Epoch 65/200\n",
      " - 26s - loss: 0.3310 - acc: 0.8901\n",
      "Epoch 66/200\n",
      " - 26s - loss: 0.3305 - acc: 0.8890\n",
      "Epoch 67/200\n",
      " - 25s - loss: 0.3306 - acc: 0.8893\n",
      "Epoch 68/200\n",
      " - 31s - loss: 0.3317 - acc: 0.8894\n",
      "Epoch 69/200\n",
      " - 26s - loss: 0.3274 - acc: 0.8914\n",
      "Epoch 70/200\n",
      " - 25s - loss: 0.3324 - acc: 0.8899\n",
      "Epoch 71/200\n",
      " - 25s - loss: 0.3261 - acc: 0.8912\n",
      "Epoch 72/200\n",
      " - 25s - loss: 0.3297 - acc: 0.8898\n",
      "Epoch 73/200\n",
      " - 24s - loss: 0.3196 - acc: 0.8941\n",
      "Epoch 74/200\n",
      " - 30s - loss: 0.3205 - acc: 0.8931\n",
      "Epoch 75/200\n",
      " - 26s - loss: 0.3188 - acc: 0.8941\n",
      "Epoch 76/200\n",
      " - 25s - loss: 0.3263 - acc: 0.8915\n",
      "Epoch 77/200\n",
      " - 25s - loss: 0.3234 - acc: 0.8926\n",
      "Epoch 78/200\n",
      " - 26s - loss: 0.3221 - acc: 0.8926\n",
      "Epoch 79/200\n",
      " - 28s - loss: 0.3153 - acc: 0.8947\n",
      "Epoch 80/200\n",
      " - 29s - loss: 0.3193 - acc: 0.8929\n",
      "Epoch 81/200\n",
      " - 27s - loss: 0.3168 - acc: 0.8945\n",
      "Epoch 82/200\n",
      " - 28s - loss: 0.3127 - acc: 0.8956\n"
     ]
    }
   ],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "print('Train...')\n",
    "\n",
    "history = classify_model.fit(x_data, y_data, \\\n",
    "            #validation_data=(x_eval, y_eval), \\\n",
    "            epochs=200, shuffle=True, batch_size=1000, \\\n",
    "            callbacks=[TQDMNotebookCallback()], verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 200 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/weKQPGcGwsjdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff10d06d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYZHV97/H3t7au3runu5l9A0ZkEQcYBhQ0XA0EcEEj\nQQhoRJ8QE5PAE7JoTGL05t5rYq4agop4xSUhaBRRTEADCipRkJlhHGaDGWCG6dmnp/fu6u6q+t4/\n6nRR01NV07NUV0+fz+t56pmqc35V9e3TNfXp3/md8zvm7oiIiABEql2AiIhMHwoFERHJUyiIiEie\nQkFERPIUCiIikqdQEBGRPIWCyCSZ2VfN7O8m2Xabmf368b6OyFRTKIiISJ5CQURE8hQKMqMEu23+\nzMzWmdmgmX3ZzGab2cNm1m9mj5pZa0H7t5vZBjPrMbPHzezMgnXnmdma4HnfBJIT3uutZrY2eO7P\nzezcY6z5d81sq5kdNLMHzWxesNzM7DNmts/M+szsWTM7J1h3tZltDGrbaWZ/ekwbTGQChYLMRO8C\nLgdeBbwNeBj4S6CD3Gf+jwHM7FXAfcBtwbqHgO+bWcLMEsB3gX8BZgHfCl6X4LnnAfcAvwe0AV8E\nHjSzmqMp1MzeBPwf4DpgLrAd+Eaw+grgjcHP0Ry06QrWfRn4PXdvBM4Bfnw07ytSikJBZqJ/dve9\n7r4T+BnwlLs/4+4p4AHgvKDdu4H/dPdH3H0M+EegFng9cDEQBz7r7mPu/m3g6YL3uAX4ors/5e4Z\nd/8aMBI872jcCNzj7mvcfQT4CPA6M1sCjAGNwKsBc/dN7r47eN4YcJaZNbl7t7uvOcr3FSlKoSAz\n0d6C+8NFHjcE9+eR+8scAHfPAjuA+cG6nX7ojJHbC+4vBm4Pdh31mFkPsDB43tGYWMMAud7AfHf/\nMXAn8Dlgn5ndbWZNQdN3AVcD283sJ2b2uqN8X5GiFAoSZrvIfbkDuX345L7YdwK7gfnBsnGLCu7v\nAP6Xu7cU3Orc/b7jrKGe3O6onQDufoe7XwCcRW430p8Fy59292uAU8jt5vr3o3xfkaIUChJm/w68\nxczebGZx4HZyu4B+DvwCSAN/bGZxM/tNYGXBc78EfNDMLgoGhOvN7C1m1niUNdwH3Gxmy4PxiP9N\nbnfXNjO7MHj9ODAIpIBsMOZxo5k1B7u9+oDscWwHkTyFgoSWuz8H3AT8M3CA3KD029x91N1Hgd8E\n3gccJDf+8J2C564Cfpfc7p1uYGvQ9mhreBT4a+B+cr2T04Drg9VN5MKnm9wupi7gU8G69wDbzKwP\n+CC5sQmR42a6yI6IiIxTT0FERPIUCiIikqdQEBGRPIWCiIjkxapdwNFqb2/3JUuWVLsMEZGTyurV\nqw+4e8eR2p10obBkyRJWrVpV7TJERE4qZrb9yK20+0hERApULBTMLGlmvzSzXwVTE3+8SBszszuC\naYPXmdn5lapHRESOrJK7j0aAN7n7QHCa/hNm9rC7P1nQ5ipgWXC7CPhC8K+IiFRBxUIhmF1yIHgY\nD24TT5++Bvh60PZJM2sxs7kF0wNPytjYGJ2dnaRSqeOue7pLJpMsWLCAeDxe7VJEZAaq6ECzmUWB\n1cDpwOfc/akJTeaTm21yXGew7JBQMLNbyM1fz6JFhRNVBk/q7KSxsZElS5Zw6KSWM4u709XVRWdn\nJ0uXLq12OSIyA1V0oDm4+MhyYAGwcvxSgsfwOne7+wp3X9HRcfgRValUira2thkdCABmRltbWyh6\nRCJSHVNy9JG79wCPAVdOWLWT3Pz14xYEy47aTA+EcWH5OUWkOip59FGHmbUE92vJXTN384RmDwLv\nDY5CuhjoPdrxhMlKjWXY05sindG08yIipVSypzAXeMzM1pG7tu0j7v4fZvZBM/tg0OYh4EVyc9F/\nCfiDShWTGsuwrz9FOnvipwrv6enh85///FE/7+qrr6anp+eE1yMicqwqefTROl65QHrh8rsK7jvw\noUrVUGh8r0slLh8xHgp/8AeHZlo6nSYWK72JH3rooRNfjIjIcTjpprk4Vsb4vvgTnwof/vCHeeGF\nF1i+fDnxeJxkMklrayubN2/m+eef5x3veAc7duwglUpx6623cssttwCvTNkxMDDAVVddxaWXXsrP\nf/5z5s+fz/e+9z1qa2tPeK0iIuXMuFD4+Pc3sHFX32HLM1knNZahNhElcpSDtWfNa+Jjbzu75PpP\nfvKTrF+/nrVr1/L444/zlre8hfXr1+cPG73nnnuYNWsWw8PDXHjhhbzrXe+ira3tkNfYsmUL9913\nH1/60pe47rrruP/++7npppuOqk4RkeM140JhOli5cuUh5xHccccdPPDAAwDs2LGDLVu2HBYKS5cu\nZfny5QBccMEFbNu2bcrqFREZN+NCodRf9P2pMV46MMhpHQ3U11T2x66vr8/ff/zxx3n00Uf5xS9+\nQV1dHZdddlnR8wxqamry96PRKMPDwxWtUUSkmNDMkjo+plCJgebGxkb6+/uLruvt7aW1tZW6ujo2\nb97Mk08+WbSdiMh0MON6CqXkjz6qwEBzW1sbl1xyCeeccw61tbXMnj07v+7KK6/krrvu4swzz+SM\nM87g4osvPuHvLyJyophX4k/nClqxYoVPvMjOpk2bOPPMM8s+b3AkzQv7B1jaXk9j8uSeTG4yP6+I\nSCEzW+3uK47ULjy7jyp4noKIyEwRnlCodgEiIieBGRMKR94NFgw0V2BMYSqdbLv7ROTkMiNCIZlM\n0tXVVfYLcybsPhq/nkIymax2KSIyQ82Io48WLFhAZ2cn+/fvL9lmLJNlb98IY11x6hIn7489fuU1\nEZFKOHm/HQvE4/EjXonspQODvP1fH+cz734t7zxTX6oiIsXMiN1HkxGL5PYfpTMn8f4jEZEKC00o\nRIJQyJ7MgwoiIhUWmlAY7ynowmsiIqWFJhTGp8vOZJUKIiKlhCYUXukpaPeRiEgpoQmF8TGFSlyj\nWURkpghNKMQ00CwickShCYWoegoiIkcUulDIKhREREoKTyiYegoiIkcSmlCIRAwz9RRERMoJTShA\nrregnoKISGnhCoWIkdHRRyIiJYUvFDQhnohISRULBTNbaGaPmdlGM9tgZrcWaXOZmfWa2drg9jeV\nqgfUUxAROZJKXk8hDdzu7mvMrBFYbWaPuPvGCe1+5u5vrWAdedGIaZoLEZEyKtZTcPfd7r4muN8P\nbALmV+r9JiOmUBARKWtKxhTMbAlwHvBUkdWvN7N1ZvawmZ1dyToiplAQESmn4pfjNLMG4H7gNnfv\nm7B6DbDI3QfM7Grgu8CyIq9xC3ALwKJFi465FvUURETKq2hPwczi5ALhXnf/zsT17t7n7gPB/YeA\nuJm1F2l3t7uvcPcVHR0dx1xPRKEgIlJWJY8+MuDLwCZ3/3SJNnOCdpjZyqCerkrVFNPRRyIiZVVy\n99ElwHuAZ81sbbDsL4FFAO5+F3At8PtmlgaGgevdK/etHYnojGYRkXIqFgru/gRgR2hzJ3BnpWqY\nKBYxzX0kIlJGqM5ojmjuIxGRskIVClH1FEREygpVKMQ0piAiUlaoQiESMV2jWUSkjFCFQixipDVL\nqohISaEKhYjpPAURkXJCFQqxqM5oFhEpJ1ShoAnxRETKC1UoxDTQLCJSVqhCIaqBZhGRskIXCuop\niIiUFrpQ0MlrIiKlhSwUIprmQkSkjHCFgqGegohIGeEKhUhEh6SKiJQRslBAoSAiUkbIQiGiaS5E\nRMoIWSiopyAiUk6oQiGmMQURkbJCFQqa+0hEpLxQhYJmSRURKS9UoaCegohIeaEKhVhEF9kRESkn\nVKEQieR6Cq5gEBEpKlShEIsYANqDJCJSXKhCIRqEQjqbrXIlIiLTUyhDQZkgIlJcuELB1FMQESmn\nYqFgZgvN7DEz22hmG8zs1iJtzMzuMLOtZrbOzM6vVD2QG2gG9RREREqJVfC108Dt7r7GzBqB1Wb2\niLtvLGhzFbAsuF0EfCH4tyJiGlMQESmrYj0Fd9/t7muC+/3AJmD+hGbXAF/3nCeBFjObW6maxnsK\nOldBRKS4KRlTMLMlwHnAUxNWzQd2FDzu5PDgwMxuMbNVZrZq//79x1zHeE9BZzWLiBRX8VAwswbg\nfuA2d+87ltdw97vdfYW7r+jo6DjmWsYHmhUKIiLFVTQUzCxOLhDudffvFGmyE1hY8HhBsKwiouop\niIiUVcmjjwz4MrDJ3T9dotmDwHuDo5AuBnrdfXelalIoiIiUV8mjjy4B3gM8a2Zrg2V/CSwCcPe7\ngIeAq4GtwBBwcwXreeXkNQ00i4gUVbFQcPcnADtCGwc+VKkaJnplmguFgohIMeE6o1m7j0REygpX\nKOjoIxGRssIVClGFgohIOeEKBfUURETKClUo6IxmEZHyQhUKEYWCiEhZoQqFmCbEExEpK1ShENF5\nCiIiZYUqFGL5i+woFEREiglVKERMPQURkXJCFQqxqHoKIiLlhCoUouopiIiUFa5Q0CypIiJlhTIU\n0hmFgohIMaEMBZ2nICJSXDhDQWMKIiJFKRRERCQvXKGgWVJFRMqaVCiY2a1m1mQ5XzazNWZ2RaWL\nO9HUUxARKW+yPYX3u3sfcAXQCrwH+GTFqqoQhYKISHmTDQUL/r0a+Bd331Cw7KSho49ERMqbbCis\nNrP/IhcKPzSzRiBbubIqQz0FEZHyYpNs9wFgOfCiuw+Z2Szg5sqVVRkaaBYRKW+yPYXXAc+5e4+Z\n3QT8FdBbubIqI6rrKYiIlDXZUPgCMGRmrwVuB14Avl6xqirEzIiYZkkVESllsqGQdncHrgHudPfP\nAY2VK6tyYpGIegoiIiVMdkyh38w+Qu5Q1DeYWQSIV66syolENEuqiEgpk+0pvBsYIXe+wh5gAfCp\nilVVQbFIRAPNIiIlTCoUgiC4F2g2s7cCKXcvO6ZgZveY2T4zW19i/WVm1mtma4Pb3xx19ccgYjr6\nSESklMlOc3Ed8Evgt4DrgKfM7NojPO2rwJVHaPMzd18e3D4xmVqOVyyqnoKISCmTHVP4KHChu+8D\nMLMO4FHg26We4O4/NbMlx1vgiRYx00CziEgJkx1TiIwHQqDrKJ5bzuvNbJ2ZPWxmZ5dqZGa3mNkq\nM1u1f//+43rDWMR0SKqISAmT7Sn8wMx+CNwXPH438NBxvvcaYJG7D5jZ1cB3gWXFGrr73cDdACtW\nrDiub/RoRD0FEZFSJjvQ/GfkvpTPDW53u/tfHM8bu3ufuw8E9x8C4mbWfjyvORnRiOmQVBGREibb\nU8Dd7wfuP1FvbGZzgL3u7ma2klxAdZ2o1y9FPQURkdLKhoKZ9QPFvkENcHdvKvPc+4DLgHYz6wQ+\nRnDCm7vfBVwL/L6ZpYFh4PrgrOmKimpMQUSkpLKh4O7HPJWFu99whPV3Ance6+sfq6gZ6exJN+u3\niMiUCNU1miHXU9B5CiIixYUuFGriEUbS6imIiBQTulCoT8QYHElXuwwRkWkpfKFQE2VwJFPtMkRE\npqXwhUIixuCoegoiIsWELxRqtPtIRKSU0IVCXU2UwVHtPhIRKSZ0odCQiDGazjKW0RFIIiIThS4U\n6mpy5+sNabBZROQwoQuF+kQUgAENNouIHCZ8oZDvKSgUREQmCmEo5HoKGmwWETlc+EIhkesp6LBU\nEZHDhS8UahQKIiKlhDcUNNAsInKY8IVCcPSR5j8SETlc+EJBu49EREoKXSjUxnX0kYhIKaELhUjE\nqEtE1VMQESkidKEAuV1IQxpoFhE5TDhDIaEL7YiIFBPOUNA1FUREigpnKOjqayIiRYUzFHSdZhGR\nokIZCnU16imIiBQTylBoSGhMQUSkmFCGQl1NVFdeExEpIpShMD7Q7O7VLkVEZFqpWCiY2T1mts/M\n1pdYb2Z2h5ltNbN1ZnZ+pWqZqL4mRtYhNZadqrcUETkpVLKn8FXgyjLrrwKWBbdbgC9UsJZDvHL1\nNY0riIgUqlgouPtPgYNlmlwDfN1zngRazGxupeoppKuviYgUV80xhfnAjoLHncGyw5jZLWa2ysxW\n7d+//7jfON9T0GCziMghToqBZne/291XuPuKjo6O4369pmQcgJ7h0eN+LRGRmaSaobATWFjweEGw\nrOIWtNYBsOPg0FS8nYjISaOaofAg8N7gKKSLgV533z0VbzyvJUksYmzvUiiIiBSKVeqFzew+4DKg\n3cw6gY8BcQB3vwt4CLga2AoMATdXqpaJYtEIC1pr2a6egojIISoWCu5+wxHWO/ChSr3/kSxqq2d7\n12C13l5EZFo6KQaaK2HxrDq2dw3prGYRkQLhDYW2OvpTaXqGxqpdiojItBHiUKgH0LiCiEiBEIdC\n7rBUjSuIiLwitKGwaNZ4KKinICIyLrShkIxHmd1Uo1AQESkQ2lAAWNJWz4sHBqpdhojItBHqUDh3\nQTMbdvUxmtZ1FUREIOShsHxhK6PpLJt291W7FBGRaSHUoXDeohYA1u7oqXIlIiLTQ6hDYW5zktlN\nNTzzcne1SxERmRZCHQpmxnkLW3lGPQURESDkoQCwfFEL27uGODioC+6IiIQ+FM5f1ArAE1sPVLkS\nEZHqC30oXLC4lQWttfzbU9urXYqISNWFPhSiEeOmixfz5IsHeX5vf7XLERGpqtCHAsB1KxaSiEX4\n+i+2VbsUEZGqUigAs+oTvHP5fP796U62HdCsqSISXgqFwO1XvIp41Pif/7Gx2qWIiFSNQiFwSlOS\nP37zMn60eR8/WL+72uWIiFSFQqHAzZcs5dwFzfz5t9exQ1dkE5EQUigUSMQi3HnD+Tjwga89zdZ9\nOhpJRMJFoTDBorY6vnDjBRwYGOUtdzzBV/77JbJZr3ZZIiJTQqFQxKXL2vnBbW/g9ae18fHvb+QD\nX3ua4dFMtcsSEak4hUIJpzQmued9F/KJa87mJ8/v5/1ffZrBkXS1yxIRqSiFQhlmxntft4RPX7ec\np17q4jc++1Mef25ftcsSEakYhcIkvOO8+dz3uxdTE4vwvq88zce/v0G9BhGZkcz95BpEXbFiha9a\ntaoq7z2SzvDJhzfzlf/eRjRinLugmbedO4/XLGhmTlOShbPqqlKXiMiRmNlqd19xxHaVDAUzuxL4\nJyAK/D93/+SE9ZcB3wNeChZ9x90/Ue41qxkK41ZvP8hjm/fz48372Bhc39kM/uLKV/N7bzwVM6tq\nfSIiE1U9FMwsCjwPXA50Ak8DN7j7xoI2lwF/6u5vnezrTodQKPTi/gF29gzzjad38J/rdvPahS38\njzM6eMOyDpYvbCEaUUCISPVNNhRiFaxhJbDV3V8MCvoGcA0woyYXOrWjgVM7Grj09HZWLG7lu2t3\n8U8/2sJnH93COfOb+MKNF2i3koicNCo50Dwf2FHwuDNYNtHrzWydmT1sZmcXeyEzu8XMVpnZqv37\n91ei1uNmZtx8yVK+96FLWPNXl/MP157L9q4h3nbnE/zjD5/j5S5NmyEi01+1jz5aAyxy93OBfwa+\nW6yRu9/t7ivcfUVHR8eUFngsWusTXLdiIQ/+4aWct7CFzz++lTd+6jFuuPtJvvvMTlJjOhFORKan\nSobCTmBhweMFwbI8d+9z94Hg/kNA3MzaK1jTlFraXs9Xbl7Jf3/4Tdx++avo7Bnitm+u5bJPPc4P\n1u+pdnkiIoep5EBzjNxA85vJhcHTwG+7+4aCNnOAve7uZrYS+Daw2MsUNd0Gmo9GNuv8/IUu/u4/\nN7J5Tz+XnzWbmy5ezMsHh2hKxkjGo+zsHua1C1s4f1GLjmISkROm6gPN7p42sz8EfkjukNR73H2D\nmX0wWH8XcC3w+2aWBoaB68sFwskuEjEuXdbO9//oUr78xEt89tHneWTj3qJtl7bXc8npbbzzvPlc\nsHjWFFcqImGlk9eqaFfPMFv2DbDslAYGR9IMj2WY3ZTksc37+MGGPTz90kEGRzNctHQWf/im0zlj\ndiMDI2nmtdSSjEerXb6InESqfp5CpcykUDiSodE09/1yB1/66Yvs6Usdsm7lklncePEi6hMx5rYk\nOWtuEwcGRhnNZJnTlNT5ESJyCIXCDDKSzvDQs7sZGMlQF4+y/eAQ96/uZGfPcL5NMh4hNZYFIBYx\n5rYkmdOUpKEmRs/wGLXxKJefNZsz5zaRzTobdvXx2oUtXLikVWMXIiGgUJjhxjJZ1u/sJWLGln0D\nPNvZw6K2emrjUXb2DLHj4DD7+0foHxmjuTbOvr4RtuwbOOx1Xj2nkcvPms1vXbCQRW06yU5kplIo\nyGF2HBxie9cQGXdePaeRRzft5YE1O1nzcjfRiHHFWXPoS43Rl0rj7rTWJUjGI8SiEU5tr2fZ7EbO\nmtvIaR0N6l2InGQUCjJpe/tSfOaR53nsuX3MaUrSUpcA4ODgKKPpLKl0hh0Hhxi/KukZsxs5pamG\nX+3oAeC0Uxq4YeUi9vePsL9/hDnNSa44azandjTk38Pd6R7K9Vo03iEy9RQKckKlxjK8dGCQVdu7\nuX91J8OjGS5Y0ko8Yvx0ywFeOjAIQENNjIGRNGZw5pwm0tksQ6MZugdHGRzN0N6Q4JLT26mNR4Pe\nhjM4kqGtIcGC1jo27OqlLhHloqVt7O1L0dFYw9WvmUs8+sp5lnv7UnR2D7NwVi2z6hLEotU+MV9k\n+lMoyJTJZp11O3tZ2FpLW0MN+/pT3Pvkyzyzo4e6eJS6mijNtXHmNdeytrOHZ7Z3k3EnkxsXp74m\nyt6+FKmxLO0NCYZGMwwVXBN7TlOS5to4kYiRiBrrdvZS+LGd05TkTWeeQmosw/7+EeY2J3nV7EYW\nt9UzNJqmoSbGnOYk85praamLk3V4ettB+lNp5rfUMr+1lqZk7JBdYiPpDDUxHfYrM4dCQU4q6UyW\nrsFRTmmsYSSd5fm9/cxvqWXtjh6+taoTJxci/akxLj61jdfMb2ZnzzDdQ6Ns2t3H48/tp7k2zpzm\nJLt6UhwYGCn6Psl4hHg0Qn/q0CvnzW1OsnLpLA4MjLB13wB7+0boaKzh9ae18f5LltJSF6d3eAwA\nw0ilM+zqGaY/lSZixuK2Os6e15Tf9TY8mmFnzxCNyTgtdXEFjFSdQkFCJZt1IgVjFQcGRujsHqY+\nEWVgJM2e3hS7elPs6R1mYCTNG5Z1MK+lll09w+zsHuaZHd2s2d7D7KYaTj+lkYWzatneNcSjG/fS\nP8lLr5rBoll1pDPO7t7h/BgM5HartdbHmdOUZE5zLTu7h0iNZZnXkqQ2ESMeNeKRCBl3IpabVHFw\nJE3W4aKlszAzugZGqE/ESKUz7OlN8fzeARa31fGu8xcwmskyGOy2W3ZKIx2NNbg7nd25n3dxWx2x\nSIRYxA7ZThIeCgWRE6AvNcZD63YTjRitQS/AgUQswvyWJE3JOGNZZ9uBQVZv7+a5Pf3UxCMsaK3j\ntI56BkbSdA+O0jU4ysHBUXb3ptjTm2Juc5K6RJQ9fSOMjGUYzWQZy2SJRSKMZbIcHBylMRkjnfXD\nejWQOxdlcVsd27uGSGcP/z9cl4gSMWNgQqDVJaKcPa+JvX0jDIykOW9hC3U1MYZH0wyOZNjVO0xq\nLMNbXjOPxW11HBwcpXtolIFUmsHRNEOjGZqScZa21zOayWJAc12cltoEqbEMO7qHiJjR3lDDOfOb\nWNhaRzRivHxwiNpElHnNtXQ01tA9NMrLB4foGx6jMRlnSVsdbQ01+TpH01mGRzMkYhHGsllG07nt\nM5rOEotGaG9IqPd1lBQKIjNAJuts2NVLTSyaH29JxqO01sWJRSPs7Uvxsy0HaKmN50Nk0+4+9vSm\nGMtkWTa7kebaODu6h8hmnf39I6zf1cecplword3RQybr1Cai1MajzG5Oks5k+fHmfYxlct8NzbVx\nmmpj1Cdi1CaidA3kvtBrYhGc3Bf4uPpE7gCCiWFUyAyKfe2cfkoDpwZh89SLBxk+whTzzbVxauNR\nBkfTxILQPmteExEzhkZzu/XaGmroaEiQdci4M5rO0jUwQtfgKP2pdO7s/6jRN5w7Mq6tPkFbQw2z\n6hO0NyRoSsbZ05dib99ILjhHM8SixmntDfmQXNJWTzIeYWAkTWf3MKef0sAbl3XwzI5uRtJZ5jXX\nMrclSSbjdA2OMK+lFsPo7B5iYCRNNJKrs60+QSxi9KXSJGIR6uLRQ3p12awzls0ecxgqFETkmPWl\nxhhLZ2mujRc9uiuT9fyhxamxDD1DY0QjRntDAjOjd2iMDbt72dWTC6fFbXWkxjLs6kmxty9FS12C\nJW11+bGa5/cO8OSLXezpTZF156KlbSxpr2c0nSUeNRKxCIlobjxoNJPlQP8IBwZGGB7LUJeIkck6\ne/tSbNrTR9SM2kSMbNY5EARAxCAaMeLRCG0NCdobaqhPxNjTlyKbdRqTMfpSaboGRugr0jODXJjV\nxaOMZZzRTLZom8K25b5aj7R+vE1DTYymZBwz2Nc3wgd/7VT+5Iozyj+x5OspFEREcPejOtlyNJ2l\ne2iUroFReoZHmd2UZG5zMn8YdTqTZWfPMPU1MWrjUbZ1DZLOOPU1UeY01/LzrQdYtb2bFYtbaWtI\nsKsnxe7e4fxutc7uITJZWNJel9v9GOwu7ArOC2qpyy0bSKXpS6UZGEmTyTqzm5K8YVk7l5x+bJec\nUSiIiEjeZENBZ/2IiEieQkFERPIUCiIikqdQEBGRPIWCiIjkKRRERCRPoSAiInkKBRERyTvpTl4z\ns/3A9mN8ejtw4ASWcyJN19pU19GZrnXB9K1NdR2dY61rsbt3HKnRSRcKx8PMVk3mjL5qmK61qa6j\nM13rgulbm+o6OpWuS7uPREQkT6EgIiJ5YQuFu6tdQBnTtTbVdXSma10wfWtTXUenonWFakxBRETK\nC1tPQUREylAoiIhIXmhCwcyuNLPnzGyrmX24inUsNLPHzGyjmW0ws1uD5X9rZjvNbG1wu7oKtW0z\ns2eD918VLJtlZo+Y2Zbg39Yq1HVGwXZZa2Z9ZnZbNbaZmd1jZvvMbH3BspLbyMw+EnzmnjOz35ji\nuj5lZpvNbJ2ZPWBmLcHyJWY2XLDd7priukr+3qZqe5Wp7ZsFdW0zs7XB8inZZmW+H6buM+buM/4G\nRIEXgFOohpRGAAAFNUlEQVSBBPAr4Kwq1TIXOD+43wg8D5wF/C3wp1XeTtuA9gnL/gH4cHD/w8Df\nT4Pf5R5gcTW2GfBG4Hxg/ZG2UfB7/RVQAywNPoPRKazrCiAW3P/7grqWFLarwvYq+nubyu1VqrYJ\n6/8v8DdTuc3KfD9M2WcsLD2FlcBWd3/R3UeBbwDXVKMQd9/t7muC+/3AJmB+NWqZpGuArwX3vwa8\no4q1ALwZeMHdj/Ws9uPi7j8FDk5YXGobXQN8w91H3P0lYCu5z+KU1OXu/+Xu41ehfxJYUIn3Ptq6\nypiy7XWk2ix3UefrgPsq9f4lair1/TBln7GwhMJ8YEfB406mwRexmS0BzgOeChb9UdDVv6cau2kA\nBx41s9VmdkuwbLa77w7u7wFmV6GuQtdz6H/Uam8zKL2NptPn7v3AwwWPlwa7QX5iZm+oQj3Ffm/T\naXu9Adjr7lsKlk3pNpvw/TBln7GwhMK0Y2YNwP3Abe7eB3yB3O6t5cBucl3XqXapuy8HrgI+ZGZv\nLFzpuf5q1Y5hNrME8HbgW8Gi6bDNDlHtbVSMmX0USAP3Bot2A4uC3/WfAP9mZk1TWNK0+70VcQOH\n/vExpdusyPdDXqU/Y2EJhZ3AwoLHC4JlVWFmcXK/8Hvd/TsA7r7X3TPungW+RAW7zaW4+87g333A\nA0ENe81sblD3XGDfVNdV4CpgjbvvhemxzQKltlHVP3dm9j7grcCNwZcJwa6GruD+anL7oV81VTWV\n+b1VfXsBmFkM+E3gm+PLpnKbFft+YAo/Y2EJhaeBZWa2NPhr83rgwWoUEuyr/DKwyd0/XbB8bkGz\ndwLrJz63wnXVm1nj+H1yg5TryW2n3wma/Q7wvamsa4JD/nqr9jYrUGobPQhcb2Y1ZrYUWAb8cqqK\nMrMrgT8H3u7uQwXLO8wsGtw/NajrxSmsq9Tvrarbq8CvA5vdvXN8wVRts1LfD0zlZ6zSo+nT5QZc\nTW4k/wXgo1Ws41JyXb91wNrgdjXwL8CzwfIHgblTXNep5I5i+BWwYXwbAW3Aj4AtwKPArCptt3qg\nC2guWDbl24xcKO0Gxsjtv/1AuW0EfDT4zD0HXDXFdW0lt795/HN2V9D2XcHveC2wBnjbFNdV8vc2\nVdurVG3B8q8CH5zQdkq2WZnvhyn7jGmaCxERyQvL7iMREZkEhYKIiOQpFEREJE+hICIieQoFERHJ\nUyiITCEzu8zM/qPadYiUolAQEZE8hYJIEWZ2k5n9MpgA7YtmFjWzATP7TDDP/Y/MrCNou9zMnrRX\nrlvQGiw/3cweNbNfmdkaMzstePkGM/u25a51cG9wFqvItKBQEJnAzM4E3g1c4rkJ0DLAjeTOql7l\n7mcDPwE+Fjzl68BfuPu55M7UHV9+L/A5d38t8HpyZ89CbubL28jNhX8qcEnFfyiRSYpVuwCRaejN\nwAXA08Ef8bXkJiDL8sokaf8KfMfMmoEWd/9JsPxrwLeCeaTmu/sDAO6eAghe75cezKsTXNlrCfBE\n5X8skSNTKIgczoCvuftHDllo9tcT2h3rHDEjBfcz6P+hTCPafSRyuB8B15rZKZC/Pu5icv9frg3a\n/DbwhLv3At0FF115D/ATz101q9PM3hG8Ro2Z1U3pTyFyDPQXisgE7r7RzP4K+C8zi5CbRfNDwCCw\nMli3j9y4A+SmMr4r+NJ/Ebg5WP4e4Itm9ongNX5rCn8MkWOiWVJFJsnMBty9odp1iFSSdh+JiEie\negoiIpKnnoKIiOQpFEREJE+hICIieQoFERHJUyiIiEje/wdmx1Sqm2ApYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff10d0392e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'eval'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Apply Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 507\n",
      "200000 56\n"
     ]
    }
   ],
   "source": [
    "file_read = open(\"../imgtvgene_sequence_classification/naive.txt\")\n",
    "\n",
    "source_sequence = []\n",
    "target_sequence = []\n",
    "\n",
    "max_count = 200000\n",
    "max_source_len = 0\n",
    "\n",
    "vgene_tag = []\n",
    "vgene_dic = {}\n",
    "vgenes = 0\n",
    "\n",
    "count = 0\n",
    "\n",
    "line = file_read.readline()\n",
    "for line in file_read:\n",
    "    split = line.strip().split(\" \")\n",
    "    #print(split)\n",
    "    \n",
    "    try:\n",
    "        source = [char_to_int[x] for x in split[2][1:-1]]\n",
    "        if max_source_len < len(source):\n",
    "            max_source_len = len(source)\n",
    "\n",
    "        target = [char_to_int[x] for x in split[3][1:-1] if x in \"NACGT\"]\n",
    "        \n",
    "        assert(len(target) < len(source))\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    source_sequence.append(source)\n",
    "    target_sequence.append(target)\n",
    "    \n",
    "    vgene_name = split[-1][1:-1].split(\"*\")[0]\n",
    "    #* for Gene /- for Family /No Split for Allele\n",
    "    if not vgene_name in vgene_dic:\n",
    "        vgene_dic[vgene_name] = vgenes\n",
    "        vgenes += 1\n",
    "    vgene_tag.append(vgene_dic[vgene_name])\n",
    "    \n",
    "    count += 1\n",
    "    #print(split[1], vgene_name)\n",
    "    if count == max_count:\n",
    "        break\n",
    "    \n",
    "print(len(source_sequence), max_source_len)\n",
    "print(len(vgene_tag), vgenes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 3, 4, 3, 2, 1, 3, 2, 4, 3, 2, 1, 3, 3, 1, 3, 4, 2, 3, 3,\n",
       "       3, 2, 2, 2, 1, 3, 3, 1, 2, 4, 3, 3, 4, 3, 1, 1, 3, 2, 2, 4, 4, 2,\n",
       "       3, 3, 1, 3, 1, 2, 2, 2, 4, 3, 4, 2, 2, 2, 4, 2, 1, 4, 4, 4, 3, 2,\n",
       "       1, 2, 4, 3, 4, 2, 4, 2, 4, 3, 3, 4, 4, 1, 4, 4, 2, 2, 1, 4, 2, 1,\n",
       "       3, 2, 1, 3, 4, 3, 3, 4, 4, 4, 2, 4, 1, 2, 4, 3, 3, 3, 3, 2, 4, 3,\n",
       "       3, 1, 4, 2, 2, 3, 3, 2, 1, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3, 1, 1, 3,\n",
       "       3, 3, 3, 2, 4, 3, 3, 1, 3, 4, 3, 3, 1, 4, 4, 3, 3, 3, 1, 3, 4, 1,\n",
       "       4, 2, 4, 2, 4, 2, 1, 4, 1, 3, 4, 3, 3, 3, 1, 2, 2, 1, 2, 2, 4, 1,\n",
       "       2, 4, 1, 2, 1, 1, 2, 2, 2, 3, 4, 2, 2, 2, 4, 2, 1, 1, 3, 1, 3, 4,\n",
       "       2, 3, 1, 3, 4, 2, 1, 2, 2, 1, 4, 3, 4, 2, 1, 3, 4, 1, 3, 1, 2, 1,\n",
       "       2, 3, 4, 2, 2, 1, 3, 3, 1, 1, 2, 2, 1, 3, 4, 4, 2, 4, 2, 2, 2, 4,\n",
       "       3, 1, 1, 3, 2, 4, 3, 1, 1, 2, 4, 2, 4, 3, 4, 3, 3, 2, 2, 3, 2, 2,\n",
       "       3, 2, 1, 3, 1, 2, 1, 2, 3, 3, 2, 2, 3, 4, 3, 4, 1, 4, 4, 1, 2, 4,\n",
       "       3, 4, 3, 2, 3, 1, 3, 1, 3, 3, 3, 3, 2, 1, 2, 2, 4, 3, 3, 4, 1, 4,\n",
       "       4, 3, 1, 2, 4, 1, 2, 4, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1, 1, 4, 2,\n",
       "       2, 4, 3, 3, 4, 2, 1, 2, 2, 3, 4, 2, 4, 2, 2, 4, 2, 1, 3])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 3, 4, 3, 2, 1, 3, 2, 4, 3, 2, 1, 3, 3, 1, 3, 4, 2, 3, 3,\n",
       "       3, 2, 2, 2, 1, 3, 3, 1, 2, 4, 3, 3, 4, 3, 1, 1, 3, 2, 2, 4, 4, 2,\n",
       "       3, 3, 1, 3, 1, 2, 2, 2, 4, 3, 4, 2, 2, 2, 4, 2, 1, 2, 2, 4, 3, 2,\n",
       "       1, 2, 4, 3, 4, 2, 4, 2, 4, 3, 3, 4, 4, 1, 2, 4, 2, 2, 1, 4, 2, 1,\n",
       "       3, 2, 1, 3, 4, 3, 3, 4, 4, 1, 2, 4, 1, 2, 4, 3, 3, 3, 3, 2, 4, 3,\n",
       "       3, 1, 4, 2, 2, 3, 3, 2, 1, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3, 1, 1, 3,\n",
       "       3, 3, 3, 2, 4, 3, 3, 1, 3, 4, 3, 3, 1, 4, 4, 3, 3, 3, 1, 3, 4, 1,\n",
       "       4, 2, 4, 1, 4, 2, 1, 4, 1, 3, 4, 3, 3, 3, 1, 3, 2, 1, 2, 2, 4, 1,\n",
       "       2, 4, 1, 2, 1, 1, 2, 2, 2, 3, 4, 2, 2, 2, 4, 2, 1, 1, 3, 1, 3, 4,\n",
       "       2, 3, 1, 3, 4, 2, 1, 2, 2, 1, 4, 1, 4, 2, 1, 3, 4, 1, 3, 1, 2, 1,\n",
       "       2, 3, 4, 2, 2, 1, 1, 3, 1, 1, 2, 2, 1, 3, 4, 4, 2, 4, 2, 2, 2, 4,\n",
       "       3, 1, 1, 3, 2, 4, 3, 1, 3, 2, 4, 2, 4, 3, 4, 3, 1, 2, 2, 3, 2, 2,\n",
       "       3, 2, 1, 3, 1, 2, 1, 2, 3, 3, 2, 2, 3, 4, 3, 4, 1, 4, 4, 1, 2, 4,\n",
       "       3, 4, 3, 2, 3, 1, 3, 1, 3, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 200000 200000\n",
      "(200000, 507) (200000, 56) (200000, 507)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "source_data = pad_sequences(source_sequence, maxlen=max_source_len, padding='post', value=0)\n",
    "classes = to_categorical(vgene_tag)\n",
    "target_data = pad_sequences(target_sequence, maxlen=max_source_len, padding='post', value=0)\n",
    "\n",
    "print(len(source_sequence), len(vgene_tag), len(target_sequence))\n",
    "print(source_data.shape, classes.shape, target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 3, 4, 1, 2, 1, 3, 2, 4, 3, 2, 1, 3, 3, 1, 3, 4, 2, 3, 3,\n",
       "       3, 2, 2, 2, 1, 3, 3, 1, 2, 4, 3, 3, 4, 3, 1, 1, 3, 2, 2, 4, 4, 2,\n",
       "       3, 3, 1, 2, 1, 2, 2, 2, 4, 3, 4, 2, 2, 2, 4, 2, 1, 2, 2, 4, 3, 2,\n",
       "       3, 2, 4, 3, 4, 2, 4, 2, 4, 3, 3, 4, 4, 1, 2, 4, 2, 2, 1, 4, 2, 1,\n",
       "       3, 2, 1, 3, 4, 1, 3, 4, 1, 1, 2, 4, 3, 3, 4, 3, 3, 3, 3, 2, 4, 3,\n",
       "       3, 1, 4, 2, 2, 3, 3, 2, 1, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3, 1, 1, 3,\n",
       "       3, 3, 1, 2, 4, 3, 3, 1, 3, 4, 3, 3, 1, 4, 4, 3, 3, 3, 4, 1, 2, 1,\n",
       "       4, 2, 4, 1, 4, 4, 1, 4, 1, 3, 4, 3, 3, 3, 1, 3, 2, 1, 2, 2, 4, 1,\n",
       "       2, 4, 1, 2, 1, 1, 2, 2, 2, 3, 4, 2, 2, 2, 4, 2, 1, 1, 3, 1, 3, 4,\n",
       "       2, 3, 1, 3, 4, 2, 1, 2, 2, 1, 4, 3, 4, 2, 1, 3, 4, 1, 3, 1, 2, 1,\n",
       "       2, 3, 4, 2, 2, 1, 1, 3, 1, 1, 2, 2, 1, 3, 4, 4, 2, 4, 2, 2, 2, 4,\n",
       "       3, 1, 1, 3, 2, 4, 3, 1, 3, 2, 4, 2, 4, 3, 4, 3, 1, 2, 2, 3, 2, 2,\n",
       "       3, 4, 3, 3, 1, 2, 1, 2, 3, 3, 2, 2, 3, 4, 3, 4, 1, 4, 4, 1, 2, 4,\n",
       "       3, 4, 3, 2, 3, 1, 3, 1, 1, 1, 1, 3, 3, 4, 1, 2, 4, 2, 3, 2, 3, 3,\n",
       "       3, 3, 3, 1, 4, 2, 2, 4, 4, 2, 3, 1, 4, 2, 4, 2, 4, 3, 3, 3, 3, 2,\n",
       "       2, 3, 4, 3, 3, 2, 1, 2, 2, 2, 4, 3, 3, 4, 2, 1, 2, 4, 3, 4, 2, 4,\n",
       "       2, 2, 4, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0], dtype=int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 3, 4, 1, 2, 1, 3, 2, 4, 3, 2, 1, 3, 3, 1, 3, 4, 2, 3, 3,\n",
       "       3, 2, 2, 2, 1, 3, 3, 1, 2, 4, 3, 3, 4, 3, 1, 1, 3, 2, 2, 4, 4, 2,\n",
       "       3, 3, 1, 2, 1, 2, 2, 2, 4, 3, 4, 2, 2, 2, 4, 2, 1, 2, 2, 4, 3, 2,\n",
       "       3, 2, 4, 3, 4, 2, 4, 2, 4, 3, 3, 4, 4, 1, 2, 4, 2, 2, 1, 4, 2, 1,\n",
       "       3, 2, 1, 3, 4, 1, 3, 4, 1, 1, 2, 4, 3, 3, 4, 3, 3, 3, 3, 2, 4, 3,\n",
       "       3, 1, 4, 2, 2, 3, 3, 2, 1, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3, 1, 1, 3,\n",
       "       3, 3, 1, 2, 4, 3, 3, 1, 3, 4, 3, 3, 1, 4, 4, 3, 3, 3, 4, 1, 2, 1,\n",
       "       4, 2, 4, 1, 4, 4, 1, 4, 1, 3, 4, 3, 3, 3, 1, 3, 2, 1, 2, 2, 4, 1,\n",
       "       2, 4, 1, 2, 1, 1, 2, 2, 2, 3, 4, 2, 2, 2, 4, 2, 1, 1, 3, 1, 3, 4,\n",
       "       2, 3, 1, 3, 4, 2, 1, 2, 2, 1, 4, 3, 4, 2, 1, 3, 4, 1, 3, 1, 2, 1,\n",
       "       2, 3, 4, 2, 2, 1, 1, 3, 1, 1, 2, 2, 1, 3, 4, 4, 2, 4, 2, 2, 2, 4,\n",
       "       3, 1, 1, 3, 2, 4, 3, 1, 3, 2, 4, 2, 4, 3, 4, 3, 1, 2, 2, 3, 2, 2,\n",
       "       3, 4, 3, 3, 1, 2, 1, 2, 3, 3, 2, 2, 3, 4, 3, 4, 1, 4, 4, 1, 2, 4,\n",
       "       3, 4, 3, 2, 3, 1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(sequence, n_unique):\n",
    "    encoding = np.zeros((len(sequence), n_unique))\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        encoding[i][sequence[i]] = 1\n",
    "    \n",
    "    return encoding\n",
    "\n",
    "print(max(source_data[0]), max(target_data[0]))\n",
    "print(one_hot_encode(source_data[0], vocab_size))\n",
    "print(one_hot_encode(target_data[0], vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 507, 5)\n"
     ]
    }
   ],
   "source": [
    "source_encoded = np.array([one_hot_encode(seq, vocab_size-1) for seq in source_data[:]])\n",
    "print(source_encoded.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 507, 5)\n"
     ]
    }
   ],
   "source": [
    "target_encoded = np.array([one_hot_encode(seq, vocab_size-1) for seq in target_data[:]])\n",
    "print(target_encoded.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the encoder-decoder model\n",
    "def baseline_model(n_timesteps_in, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(150, input_shape=(n_timesteps_in, n_features)))\n",
    "    model.add(RepeatVector(n_timesteps_in))\n",
    "    model.add(LSTM(150, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_50 (LSTM)               (None, 150)               93600     \n",
      "_________________________________________________________________\n",
      "repeat_vector_16 (RepeatVect (None, 507, 150)          0         \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 507, 150)          180600    \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 507, 5)            755       \n",
      "=================================================================\n",
      "Total params: 274,955\n",
      "Trainable params: 274,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 295s - loss: 1.4697 - acc: 0.4280\n",
      "Epoch 2/10\n",
      " - 289s - loss: 1.4664 - acc: 0.4314\n",
      "Epoch 3/10\n",
      " - 289s - loss: 1.4605 - acc: 0.4344\n",
      "Epoch 4/10\n",
      " - 288s - loss: 1.4715 - acc: 0.4281\n",
      "Epoch 5/10\n",
      " - 289s - loss: 1.4668 - acc: 0.4307\n",
      "Epoch 6/10\n",
      " - 289s - loss: 1.4667 - acc: 0.4314\n",
      "Epoch 7/10\n",
      " - 289s - loss: 1.4658 - acc: 0.4314\n",
      "Epoch 8/10\n",
      " - 289s - loss: 1.4658 - acc: 0.4314\n",
      "Epoch 9/10\n",
      " - 288s - loss: 1.4662 - acc: 0.4314\n",
      "Epoch 10/10\n",
      " - 290s - loss: 1.4661 - acc: 0.4314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4779aef60>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "from custom_recurrents import AttentionDecoder\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "print('Train...')\n",
    "\n",
    "train_data_size = 10000\n",
    "test_source_len = max_source_len\n",
    "model = baseline_model(test_source_len, vocab_size-1)\n",
    "\n",
    "model.fit(source_encoded[:train_data_size, :test_source_len, :], \\\n",
    "          target_encoded[:train_data_size, :test_source_len, :], epochs=10,\n",
    "          callbacks=[TQDMNotebookCallback()], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the encoder-decoder with attention model\n",
    "def attention_model(n_timesteps_in, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(n_timesteps_in, n_features), return_sequences=True))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(AttentionDecoder(128, n_features))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_48 (LSTM)               (None, 507, 128)          68608     \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 507, 128)          131584    \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 507, 5)            151326    \n",
      "=================================================================\n",
      "Total params: 351,518\n",
      "Trainable params: 351,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 7108s - loss: 1.0921 - acc: 0.5329\n",
      "Epoch 2/10\n",
      " - 8691s - loss: 0.8611 - acc: 0.5935\n",
      "Epoch 3/10\n",
      " - 4276s - loss: 0.8217 - acc: 0.6074\n",
      "Epoch 4/10\n",
      " - 4267s - loss: 0.7832 - acc: 0.6216\n",
      "Epoch 5/10\n",
      " - 4283s - loss: 0.7716 - acc: 0.6307\n",
      "Epoch 6/10\n",
      " - 4261s - loss: 0.7997 - acc: 0.6237\n",
      "Epoch 7/10\n",
      " - 4294s - loss: 0.7596 - acc: 0.6327\n",
      "Epoch 8/10\n",
      " - 4200s - loss: 0.7529 - acc: 0.6346\n",
      "Epoch 9/10\n",
      " - 4190s - loss: 0.8213 - acc: 0.6196\n",
      "Epoch 10/10\n",
      " - 4189s - loss: 0.8638 - acc: 0.5940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb28366e358>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "\n",
    "train_data_size = 10000\n",
    "test_source_len = max_source_len #100\n",
    "model = attention_model(test_source_len, vocab_size-1)\n",
    "\n",
    "model.fit(source_encoded[:train_data_size, :test_source_len, :], \\\n",
    "          target_encoded[:train_data_size, :test_source_len, :], epochs=10,\n",
    "          callbacks=[TQDMNotebookCallback()], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_encoded[:train_data_size, :test_source_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encoded[:train_data_size, :test_source_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "11e6ce4dd2b542c1b6066d12771be950": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "146856a4475b4cc2893c78b26d644cca": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    },
    "584e749c25a74721b1da3023ccf883fe": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
